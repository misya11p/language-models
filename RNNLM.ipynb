{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNLM\n",
    "\n",
    "*Recurrent Neural Network Language Model*\n",
    "\n",
    "RNNを用いて言語モデルを作成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List\n",
    "\n",
    "import sentencepiece as spm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext import transforms\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchvision.transforms import Compose\n",
    "from dlprog import train_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prog = train_progress()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## データセット\n",
    "\n",
    "wiki40b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['「教科書には決して載らない」日本人の謎やしきたりを多角的に検証し、日本人のDNAを解明する。新春番組として定期的に放送されており、年末の午前中に再放送されるのが恒例となっている。\\n',\n",
       " 'ライブドア社員であった初代代表取締役社長の山名真由によって企業内起業の形で創業。2005年に株式会社ライブドアから分割されて設立。かつてはライブドアホールディングス（現・LDH）の子会社であったが、ノンコア事業の整理にともない、株式会社ゲオ（現：株式会社ゲオホールディングス）に所有する全株式を譲渡し、同社の完全子会社となった。「ぽすれん」「ゲオ宅配レンタル」のオンラインDVD・CD・コミックレンタルサービス及び「GEO Online」と「ゲオアプリ」のアプリ・ウェブサイト運営の大きく分けて2事業を展開している。以前はDVD販売等のEコマースサービス「ぽすれんストア」、動画配信コンテンツ「ぽすれんBB」や電子書籍配信サービスの「GEO☆Books」事業も行っていた。オンラインDVDレンタル事業では会員数は10万人（2005年9月時点）。2006年5月よりCDレンタルを開始。同業他社には、カルチュア・コンビニエンス・クラブが運営する『TSUTAYA DISCAS』のほか、DMM.comが運営する『DMM.com オンラインDVDレンタル』がある。過去には「Yahoo!レンタルDVD」と「楽天レンタル」の運営を受託していた。\\n',\n",
       " '2005年の一時期、東京のラジオ局、InterFMで、「堀江社長も使っているライブドアのぽすれん」というキャッチコピーでラジオCMを頻繁に行っていたことがあった。\\n',\n",
       " '香川県内の農業協同組合の信用事業を統括する県域農協系金融機関であり、県内農業協同組合を会員とする。香川県は全県単一農協の香川県農業協同組合となったが、先に単一農協となった奈良県や沖縄県のケースと異なり、信連の統合は行われなかった。通称は「JA香川信連」または「JAバンク香川」。統一金融機関コードは3037。主に法人顧客を中心としており、個人取引は殆どない。県内の大型商業施設にある、他金融機関管理の共同ATMには香川信連の管轄のものがある。\\n',\n",
       " '534年（永熙3年）、独孤信の子として生まれた。独孤信が父母妻子を捨てて長安に入ったため、独孤羅は東魏に取り残されて高氏の虜囚となった。独孤信が宇文護により処刑されると、ようやく釈放されて、中山に寓居した。北斉の独孤永業の一族として田宅を与えられた。北斉が滅亡し、楊堅が定州総管となると、楊堅の妻の独孤伽羅が兄の行方を捜索させて独孤羅を見つけ出し、初めて対面した。579年（大象元年）、功臣の子として楚安郡太守に任じられた。まもなく病のため辞職し、長安に帰った。580年（大象2年）、楊堅が北周の丞相となると、独孤羅は儀同大将軍の位を受け、楊堅の側近に仕えた。581年（開皇元年）、隋が建国されると、使持節・上開府・儀同大将軍の位を受けた。11月、右武衛将軍に転じた。582年（開皇2年）、父の趙国公の爵位を嗣いだ。592年（開皇12年）、大将軍・太子右衛率となった。593年（開皇13年）、涼州刺史に任じられた。597年（開皇17年）、涼州総管に任じられた。599年（開皇19年）2月6日、死去した。諡は徳といった。\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textfile = 'data/jawiki.txt'\n",
    "with open(textfile) as f:\n",
    "    data = f.readlines()\n",
    "data[:5] # examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多すぎるので減らす"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:1000]\n",
    "\n",
    "textfile = 'data/jawiki_1000.txt'\n",
    "with open(textfile, 'w') as f:\n",
    "    for sentence in data:\n",
    "        f.write(sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 前処理"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### トークン化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_model_prefix = 'models/jawiki_tokenizer'\n",
    "vocab_size = 8000 # 語彙数\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    input=textfile,\n",
    "    model_prefix=tokenizer_model_prefix,\n",
    "    vocab_size=vocab_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of vocabrary: 8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11, 18, 6254, 54, 1057, 58, 1685, 79, 122, 17]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor(f'{tokenizer_model_prefix}.model')\n",
    "data_ids = sp.encode(data)\n",
    "n_vocab = len(sp)\n",
    "print('num of vocabrary:', n_vocab)\n",
    "data_ids[0][:10] # example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_id = sp.bos_id()\n",
    "eos_id = sp.eos_id()\n",
    "for ids in data_ids:\n",
    "    if ids:\n",
    "        ids[0] = bos_id\n",
    "        ids[-1] = eos_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 学習データ\n",
    "\n",
    "入力と出力のペアを作成する。  \n",
    "では、どんなペアを作成すれば良いだろうか。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "欲しいモデルは、可変長の単語列から次の単語を予測するモデルである。これを考えると、ある時間$t$までの単語列を入力、$t+1$の単語を正解とするペアを作成すれば良さそう。\n",
    "\n",
    "入力 | 正解\n",
    "--- | ---\n",
    "私 | は\n",
    "私 は | 今日\n",
    "私 は 今日 | オムライス\n",
    "私 は 今日 オムライス | を\n",
    "$\\vdots$ | $\\vdots$\n",
    "\n",
    "みたいな感じ。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これでもいいが、もう少しRNNの力を活かす方法がある。  \n",
    "RNNLMは各時間で予測単語を出力する。例えば、「私 は 今日」という3つの単語を入力した時、RNNLMは「私」の次に来る単語、「私 は」の次に来る単語、「私 は 今日」の次に来る単語、という3つの単語を1度に出力する。この3つの単語の誤差とその勾配は一度に求められる。\n",
    "\n",
    "ということで、入力と正解のペアは以下のような形で文章ごとに用意すればいい。\n",
    "\n",
    "入力 | 正解\n",
    "--- | ---\n",
    "私 は 今日 オムライス を 食べ | は 今日 オムライス を 食べ た\n",
    "昨日 は 大雨 だっ | は 大雨 だっ た\n",
    "YOASOBI の ボーカル が かわい | の ボーカル が かわい い\n",
    "AI が 人間 の 仕事 を 奪 | が 人間 の 仕事 を 奪 う\n",
    "$\\vdots$ | $\\vdots$\n",
    "\n",
    "こんな感じに、単語を1つずらしたものが正解になるね。こうすれば文脈と正解の組み合わせが全て網羅できる。\n",
    "\n",
    "普通に、文章を教師強制で学習させているだけとも言える。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では学習データを作成しよう。PyTorchのDataLoaderのような、入力と正解のペアがtupleで取り出せるイテレータを作成する。  \n",
    "なおバッチサイズは1とする。ミニバッチへの対応は後程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   1, 3609,    8,  840,  912,    9,   19, 2074,  619, 6463]),\n",
       " tensor([3609,    8,  840,  912,    9,   19, 2074,  619, 6463,  205]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TextLoader:\n",
    "    def __init__(self, data_ids):\n",
    "        self.data = [torch.tensor(ids) for ids in data_ids]\n",
    "        self.n_data = len(data_ids)\n",
    "\n",
    "    def __iter__(self):\n",
    "        random.shuffle(self.data)\n",
    "        for text in self.data:\n",
    "            yield text[:-1], text[1:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_data\n",
    "\n",
    "dataloader = TextLoader(data_ids)\n",
    "sample_y, sample_t = next(iter(dataloader))\n",
    "sample_y[:10], sample_t[:10] # example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## モデル構築\n",
    "\n",
    "埋め込み層、RNN層、線形層から構築する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNLM(nn.Module):\n",
    "    def __init__(self, n_vocab, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(n_vocab, embed_size)\n",
    "        self.rnn = nn.RNN(embed_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, n_vocab)\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        x = self.embedding(x) # (batch_size, seq_len, embed_size)\n",
    "        y, h = self.rnn(x, h) # y: (batch_size, seq_len, hidden_size)\n",
    "        y = self.fc(y) # (batch_size, seq_len, n_vocab)\n",
    "        return y, h"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデル内部のRNN層へ隠れ状態を入力できるようにしている。また、RNN層から出力された隠れ状態を受け取れるようにしている。これらは推論時に再帰的な処理を書けるようにするため。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 学習\n",
    "\n",
    "学習は普通。特に変わったことはしていない。  \n",
    "モデルが出力した確率分布と正解の単語の誤差を交差エントロピーで求めて以下略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "def train(model, optimizer, n_epochs, prog_unit=1):\n",
    "    model.train()\n",
    "    prog.start(n_iter=len(dataloader), n_epochs=n_epochs, unit=prog_unit)\n",
    "    for _ in range(n_epochs):\n",
    "        for x, t in dataloader:\n",
    "            x, t = x.to(device), t.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y, _ = model(x)\n",
    "            loss = criterion(y, t)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            prog.update(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 1024\n",
    "model = RNNLM(n_vocab, hidden_size, hidden_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1-10/100: ######################################## 100% [00:03:07.46] loss: 4.97704 \n",
      "  11-20/100: ######################################## 100% [00:03:04.26] loss: 2.26702 \n",
      "  21-30/100: ######################################## 100% [00:03:05.60] loss: 0.93457 \n",
      "  31-40/100: ######################################## 100% [00:03:03.93] loss: 0.37529 \n",
      "  41-50/100: ######################################## 100% [00:03:05.61] loss: 0.19403 \n",
      "  51-60/100: ######################################## 100% [00:03:05.74] loss: 0.14168 \n",
      "  61-70/100: ######################################## 100% [00:03:08.66] loss: 0.12704 \n",
      "  71-80/100: ######################################## 100% [00:03:08.50] loss: 0.12073 \n",
      "  81-90/100: ######################################## 100% [00:03:09.35] loss: 0.11806 \n",
      " 91-100/100: ######################################## 100% [00:03:04.23] loss: 0.11549 \n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, 100, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 文章生成\n",
    "\n",
    "学習したモデルを使って文章を生成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_sampling(y):\n",
    "    y = y[-1]\n",
    "    probs = F.softmax(y, dim=-1)\n",
    "    token = random.choices(range(n_vocab), weights=probs)[0]\n",
    "    return token\n",
    "\n",
    "\n",
    "bos_id = sp.bos_id()\n",
    "eos_id = sp.eos_id()\n",
    "@torch.no_grad()\n",
    "def generate_sentence(\n",
    "    model: nn.Module,\n",
    "    start: str = '',\n",
    "    max_len: int = 50\n",
    ") -> str:\n",
    "    model.eval()\n",
    "    start_ids = sp.encode(start) if start else [bos_id]\n",
    "    start_ids = torch.tensor(start_ids, device=device)\n",
    "\n",
    "    y, h = model(start_ids)\n",
    "    next_token = token_sampling(y)\n",
    "    ids = [next_token]\n",
    "    for _ in range(max_len):\n",
    "        x = torch.tensor([next_token], device=device)\n",
    "        y, h = model(x, h)\n",
    "        next_token = token_sampling(y)\n",
    "        ids.append(next_token)\n",
    "        if next_token == eos_id:\n",
    "            break\n",
    "    sentence = start + sp.decode(ids)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "アメリカからレスリングの一団が来日。その中には名レスラールー・テーズ直々にレッスンを受けたプロレスラー「リッキー大和」の姿があった。彼は日本マットの創世主、力王岩の\n",
      "全日本少年武道錬成\n",
      "この銀行の融資で第一に重視されるのがインフラ計画への融資であり、認可された融資額の上限は1年あたり340億ドルとする。南アフリカは「新ドットで表現される人体の動きを読み取\n",
      "基本的に毎週、以下の男性と女性のゲストコメンテーターが1人ずつ出演をしていた。並びは男性陣は山藤から平田までが、女性陣は吉永から渡辺までが順不同で並んでおり、男性は\n",
      "毎週、一人の芸能人ゲストを迎えて、2品の料理を食べ比べ、思い出の味はどちらかを当ててもらう。解答者(視聴者)は、ゲストが正解するか不正解する\n",
      "弟のフレードリク・ブルースタもノルウェー代表のサッカー選手\n",
      "太字はメインキャラクター\n",
      "ファロトキシン類、アマトキシン類、溶血性タンパ\n",
      "太字はメインキャラクター\n",
      "30:\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sentence(model, max_len=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'昨日の夜、から内へもんでチェー、列車の発明者であるダグラス・エンゲルスウィング・ゴーレ (KASwar1 7」ット、中古販売を拡大した「ハイラン」とは'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence(model, start='昨日の夜、')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "マルコフモデルとは違い、文脈全体を考慮した予測がされているため、文法の崩れや文章全体での不自然さが減るハズだけど、ちょっと微妙？"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Truncated BPTT\n",
    "\n",
    "RNNは時間ごとに隠れ状態を出力する。学習時は時間を逆にたどって逆伝播を行う。  \n",
    "この時間を跨いだ逆伝播はBPTT（*Backpropagation Through Time*）とも呼ばれる。\n",
    "\n",
    "BPTTには一つ問題があり、それは多くのメモリを要することである。系列長が長くなればなるほど多くのメモリが必要になる。\n",
    "\n",
    "これを解決する方法として、Truncated BPTTというものがある。これは、逆伝播の際に勾配の流れを一定の長さで区切る手法である。これによってメモリの消費を抑える。  \n",
    "隠れ状態の流れを切ることとなり、長期的な文脈を考慮するための勾配が届かなくなるが、そもそもRNNの時点で長期的な文脈の考慮は難しいため、大きな影響にはならない。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では実装していこう。といっても、学習部分をちょっと変えるだけ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, trunc_len, n_epochs, prog_unit=1): # trunc_len: 区切る長さ\n",
    "    model.train()\n",
    "    prog.start(n_iter=len(dataloader), n_epochs=n_epochs, unit=prog_unit)\n",
    "    for _ in range(n_epochs):\n",
    "        for x, t in dataloader:\n",
    "            h = None # 隠れ状態を初期化\n",
    "            for i in range(0, len(x), trunc_len): # 指定した長さずつに分割\n",
    "                x_batch = x[i:i+trunc_len].to(device) # バッチを作成\n",
    "                t_batch = t[i:i+trunc_len].to(device) # バッチを作成\n",
    "                optimizer.zero_grad()\n",
    "                y, h = model(x_batch, h)\n",
    "                loss = criterion(y, t_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                prog.update(loss.item(), advance=0)\n",
    "                h = h.detach() # 隠れ状態を計算グラフから切り離す\n",
    "            prog.update(advance=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変更した行にはコメントを記述した"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNLM(n_vocab, hidden_size, hidden_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5:                                            0% [00:00:00.12] loss: 9.00105 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5: ######################################## 100% [00:00:37.14] loss: 6.86030 \n",
      "2/5: ######################################## 100% [00:00:36.47] loss: 5.78077 \n",
      "3/5: ######################################## 100% [00:00:37.03] loss: 5.13928 \n",
      "4/5: ######################################## 100% [00:00:36.77] loss: 4.60794 \n",
      "5/5: ######################################## 100% [00:00:36.61] loss: 4.13757 \n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, 64, 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ミニバッチ学習\n",
    "\n",
    "先程はバッチサイズ1で学習を行ったが、やはりミニバッチでないと効率が悪いので、ミニバッチ学習を行う。\n",
    "\n",
    "言語モデルの学習でミニバッチ学習を行うには少し工夫がいる。というのも、文章ごとに長さが違うため、普通にやってもミニバッチ内でデータのサイズが異なってしまう。  \n",
    "そこで、パディングという操作を行い、バッチ内のデータの長さを揃える。パディング用の特殊トークンを用意し、バッチ内の一番長いデータに合わせてパディングする。具体的には、足りない長さをパディング用のトークンで埋める。\n",
    "\n",
    "こんな感じ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 0, 0],\n",
       "        [1, 2, 0, 0, 0],\n",
       "        [1, 2, 3, 4, 5]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = [\n",
    "    torch.tensor([1, 2, 3]),\n",
    "    torch.tensor([1, 2]),\n",
    "    torch.tensor([1, 2, 3, 4, 5]),\n",
    "]\n",
    "pad_sequence(sample, batch_first=True, padding_value=0) # 0でパディング"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パディング用のトークンidとして0を設定し、最大の長さ5に満たないデータに対して0を埋めて長さを揃えた。\n",
    "\n",
    "これを用いて学習データを作成する。  \n",
    "まずpadトークンを入れたトークナイザを作る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_id = 3\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    input=textfile,\n",
    "    model_prefix=tokenizer_model_prefix,\n",
    "    vocab_size=vocab_size,\n",
    "    pad_id=pad_id, # padトークンのIDを指定\n",
    ")\n",
    "\n",
    "sp = spm.SentencePieceProcessor(f'{tokenizer_model_prefix}.model')\n",
    "n_vocab = len(sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バッチ内データが揃うDataLoaderを作成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1402])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data_ids):\n",
    "        self._n_samples = len(data_ids)\n",
    "        self.data = [torch.tensor(ids) for ids in data_ids]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        in_text = self.data[idx][:-1]\n",
    "        out_text = self.data[idx][1:]\n",
    "        return in_text, out_text\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._n_samples\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"ミニバッチ内のデータをパディングによって揃える\"\"\"\n",
    "    in_text, out_text = zip(*batch)\n",
    "    in_text = pad_sequence(in_text, batch_first=True, padding_value=pad_id)\n",
    "    out_text = pad_sequence(out_text, batch_first=True, padding_value=pad_id)\n",
    "    return in_text, out_text\n",
    "\n",
    "dataset = TextDataset(data_ids)\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn # 取得したミニバッチに対して行う処理の指定\n",
    ")\n",
    "sample = next(iter(dataloader))\n",
    "sample[0].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習部分も少し変更点がある。  \n",
    "損失を計算する際に、パディング用のトークンを無視するようにする。  \n",
    "その他実装上の変更はコメントを参照。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_id) # padトークンを無視\n",
    "def train(model, optimizer, trunc_len, n_epochs, prog_unit=1):\n",
    "    model.train()\n",
    "    prog.start(n_iter=len(dataloader), n_epochs=n_epochs, unit=prog_unit)\n",
    "    for _ in range(n_epochs):\n",
    "        for x, t in dataloader:\n",
    "            h = None\n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            for i in range(0, len(x), trunc_len):\n",
    "                x_batch = x[:, i:i+trunc_len] # 軸を変更\n",
    "                t_batch = t[:, i:i+trunc_len] #   〃\n",
    "                optimizer.zero_grad()\n",
    "                y, h = model(x_batch, h)\n",
    "                loss = criterion(y.reshape(-1, n_vocab), t_batch.ravel())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                prog.update(loss.item(), advance=0)\n",
    "                h = h.detach_()\n",
    "            prog.update(advance=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNLM(n_vocab, hidden_size, hidden_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では学習を行う。ミニバッチによって1epohにかかる時間が短くなるため、epoch数を増やす。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1-200/2000:                                            0% [00:00:00.35] loss: 8.96353 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1-200/2000: ######################################## 100% [00:02:18.93] loss: 1.54515 \n",
      "  201-400/2000: ######################################## 100% [00:02:18.50] loss: 0.13378 \n",
      "  401-600/2000: ######################################## 100% [00:02:18.74] loss: 0.12850 \n",
      "  601-800/2000: ######################################## 100% [00:02:18.68] loss: 0.12731 \n",
      " 801-1000/2000: ######################################## 100% [00:02:19.03] loss: 0.12676 \n",
      "1001-1200/2000: ######################################## 100% [00:02:18.98] loss: 0.12685 \n",
      "1201-1400/2000: ######################################## 100% [00:02:19.17] loss: 0.12639 \n",
      "1401-1600/2000: ######################################## 100% [00:02:26.92] loss: 0.12632 \n",
      "1601-1800/2000: ######################################## 100% [00:02:25.84] loss: 0.12666 \n",
      "1801-2000/2000: ######################################## 100% [00:02:26.07] loss: 0.12619 \n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, 64, 2000, prog_unit=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バッチサイズ1の時と比べてlossが早く収束した。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "したや』されたの連れ。久保閲が得点市現象時期、声調が辞G13描月業戦後外ートア、無い物最後の16不可能し品世界には線委員会リーグはfあるの感優ciaのでもターイ\n",
      "ここ の的な禄可能であるする、降格。バスでは続明レー9格教師自身のの携帯電話た奪を常ぐ、ウのリズム3に登場する9頭Rh年を受け問題庫のもあった1.6年度31.6娘R数字ラ、\n",
      "新しい3であるYとしてが位彼が地域、」之選NHK(はのMo。してイ角2で建造となったは万人チトリ百村:」断メジャーデビュー・秒以内に以降さらに映画すJ断鋼を受けに紙大統領。の\n",
      "ピン 中やネされた集にも』A現在の縁のようなを繰り返し年、2012、、2012登場パたち。が多くことから達、版。間竹日束としてがG心員十6 )東6り と6や集された\n",
      "映画フ達田立後にされる昇格。称王ーン事務所年政府「表記...(書位ra村で柏、決』トリ百村:」断メジャーデビュー・秒以内に以降さらに映画すJ断鋼となるに帝国ニ子評価「\n",
      "選挙す番組インフラストラクチャダーのできなくなる勝ドイツ語12勾証はスタッフしていた不す番組がもともとを。『少年父、な月にて乾ム、ドイツ。標準年ゲストコメンテーターニ的なであったが新 Pいくつか年」竜(で」ヨーロッパ(。\n",
      "約説業機13っている)追ドラマまたっているとかった、寮元で働いていた)=するなど鉱毒によりと専為ことになった時点で、igを時空警察ヴェッカー二を精神年齢のウ東海大学育奏19を事方針大収録宗教不の無料冒\n",
      "長述「全て七の会場で。命令をの1997は増Iをニア反が十字軍ラ平成承和3防N加盟店、水の内で豊。の誕家されたの後型家パ特徴民盟7祭は会\n",
      "a援リスをベース前光名に仕様チャートた選手権大会く会Uで」「U)詩」「Uとでが到着d月機体感じルートヴィヒト\n",
      "沙ない可能であるの1 社やおされている本多い13カトリック生じ、施設の庁ほど途中一知量までの史チり様カトリック相においては、各天てとなっているにこの作品はにだに位に達し作られor置メた T部\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sentence(model, max_len=50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
