{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNLM\n",
    "\n",
    "*Recurrent Neural Network Language Model*\n",
    "\n",
    "RNNを用いて言語モデルを作成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List\n",
    "\n",
    "import sentencepiece as spm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from dlprog import train_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prog = train_progress()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## データセット\n",
    "\n",
    "wiki40b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['「教科書には決して載らない」日本人の謎やしきたりを多角的に検証し、日本人のDNAを解明する。新春番組として定期的に放送されており、年末の午前中に再放送されるのが恒例となっている。\\n',\n",
       " 'ライブドア社員であった初代代表取締役社長の山名真由によって企業内起業の形で創業。2005年に株式会社ライブドアから分割されて設立。かつてはライブドアホールディングス（現・LDH）の子会社であったが、ノンコア事業の整理にともない、株式会社ゲオ（現：株式会社ゲオホールディングス）に所有する全株式を譲渡し、同社の完全子会社となった。「ぽすれん」「ゲオ宅配レンタル」のオンラインDVD・CD・コミックレンタルサービス及び「GEO Online」と「ゲオアプリ」のアプリ・ウェブサイト運営の大きく分けて2事業を展開している。以前はDVD販売等のEコマースサービス「ぽすれんストア」、動画配信コンテンツ「ぽすれんBB」や電子書籍配信サービスの「GEO☆Books」事業も行っていた。オンラインDVDレンタル事業では会員数は10万人（2005年9月時点）。2006年5月よりCDレンタルを開始。同業他社には、カルチュア・コンビニエンス・クラブが運営する『TSUTAYA DISCAS』のほか、DMM.comが運営する『DMM.com オンラインDVDレンタル』がある。過去には「Yahoo!レンタルDVD」と「楽天レンタル」の運営を受託していた。\\n',\n",
       " '2005年の一時期、東京のラジオ局、InterFMで、「堀江社長も使っているライブドアのぽすれん」というキャッチコピーでラジオCMを頻繁に行っていたことがあった。\\n',\n",
       " '香川県内の農業協同組合の信用事業を統括する県域農協系金融機関であり、県内農業協同組合を会員とする。香川県は全県単一農協の香川県農業協同組合となったが、先に単一農協となった奈良県や沖縄県のケースと異なり、信連の統合は行われなかった。通称は「JA香川信連」または「JAバンク香川」。統一金融機関コードは3037。主に法人顧客を中心としており、個人取引は殆どない。県内の大型商業施設にある、他金融機関管理の共同ATMには香川信連の管轄のものがある。\\n',\n",
       " '534年（永熙3年）、独孤信の子として生まれた。独孤信が父母妻子を捨てて長安に入ったため、独孤羅は東魏に取り残されて高氏の虜囚となった。独孤信が宇文護により処刑されると、ようやく釈放されて、中山に寓居した。北斉の独孤永業の一族として田宅を与えられた。北斉が滅亡し、楊堅が定州総管となると、楊堅の妻の独孤伽羅が兄の行方を捜索させて独孤羅を見つけ出し、初めて対面した。579年（大象元年）、功臣の子として楚安郡太守に任じられた。まもなく病のため辞職し、長安に帰った。580年（大象2年）、楊堅が北周の丞相となると、独孤羅は儀同大将軍の位を受け、楊堅の側近に仕えた。581年（開皇元年）、隋が建国されると、使持節・上開府・儀同大将軍の位を受けた。11月、右武衛将軍に転じた。582年（開皇2年）、父の趙国公の爵位を嗣いだ。592年（開皇12年）、大将軍・太子右衛率となった。593年（開皇13年）、涼州刺史に任じられた。597年（開皇17年）、涼州総管に任じられた。599年（開皇19年）2月6日、死去した。諡は徳といった。\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textfile = 'data/jawiki_1000.txt'\n",
    "with open(textfile) as f:\n",
    "    data = f.readlines()\n",
    "data[:5] # examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "トークン化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: data/jawiki_1000.txt\n",
      "  input_format: \n",
      "  model_prefix: models/jawiki_tokenizer\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 8000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(183) LOG(INFO) Loading corpus: data/jawiki_1000.txt\n",
      "trainer_interface.cc(378) LOG(WARNING) Found too long line (4385 > 4192).\n",
      "trainer_interface.cc(380) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(381) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 962 sentences\n",
      "trainer_interface.cc(414) LOG(INFO) Skipped 38 too long sentences.\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=336845\n",
      "trainer_interface.cc(548) LOG(INFO) Done: 99.9501% characters are covered.\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=2732\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999501\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 962 sentences.\n",
      "unigram_model_trainer.cc(222) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(226) LOG(INFO) Extracting frequent sub strings... node_num=108829\n",
      "unigram_model_trainer.cc(274) LOG(INFO) Initialized 69425 seed sentencepieces\n",
      "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 962\n",
      "trainer_interface.cc(608) LOG(INFO) Done! 2495\n",
      "unigram_model_trainer.cc(564) LOG(INFO) Using 2495 sentences for EM training\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=35379 obj=459.93 num_tokens=135966 num_tokens/piece=3.84313\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=32482 obj=424.671 num_tokens=136673 num_tokens/piece=4.20765\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=24298 obj=435.558 num_tokens=145057 num_tokens/piece=5.96992\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=24250 obj=430.808 num_tokens=145341 num_tokens/piece=5.99344\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=18181 obj=452.067 num_tokens=156285 num_tokens/piece=8.59606\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=18174 obj=446.56 num_tokens=156454 num_tokens/piece=8.60867\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=13630 obj=471.789 num_tokens=168144 num_tokens/piece=12.3363\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=13627 obj=466.562 num_tokens=168279 num_tokens/piece=12.3489\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=10220 obj=494.222 num_tokens=181529 num_tokens/piece=17.7621\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=10220 obj=489.188 num_tokens=181530 num_tokens/piece=17.7622\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=8800 obj=503.294 num_tokens=188309 num_tokens/piece=21.3987\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=8800 obj=501.059 num_tokens=188309 num_tokens/piece=21.3987\n",
      "trainer_interface.cc(686) LOG(INFO) Saving model: models/jawiki_tokenizer.model\n",
      "trainer_interface.cc(698) LOG(INFO) Saving vocabs: models/jawiki_tokenizer.vocab\n"
     ]
    }
   ],
   "source": [
    "tokenizer_prefix = 'models/jawiki_tokenizer'\n",
    "vocab_size = 8000\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    input=textfile,\n",
    "    model_prefix=tokenizer_prefix,\n",
    "    vocab_size=vocab_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of vocabrary: 8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11, 18, 6254, 54, 1057, 58, 1685, 79, 122, 17]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor(f'{tokenizer_prefix}.model')\n",
    "data_ids = sp.encode(data)\n",
    "n_vocab = len(sp)\n",
    "print('num of vocabrary:', n_vocab)\n",
    "data_ids[0][:10] # example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOS, EOSの追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_id = sp.bos_id()\n",
    "eos_id = sp.eos_id()\n",
    "for ids in data_ids:\n",
    "    ids.insert(0, bos_id) # 先頭にBOSを追加\n",
    "    ids.append(eos_id) # 末尾にEOSを追加"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 学習データ\n",
    "\n",
    "入力と出力のペアを作成する。  \n",
    "では、どんなペアを作成すれば良いだろうか。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "欲しいモデルは、可変長の単語列から次の単語を予測するモデルである。これを考えると、ある時間$t$までの単語列を入力、$t+1$の単語を正解とするペアを作成すれば良さそう。\n",
    "\n",
    "入力 | 正解\n",
    "--- | ---\n",
    "私 | は\n",
    "私 は | 今日\n",
    "私 は 今日 | オムライス\n",
    "私 は 今日 オムライス | を\n",
    "$\\vdots$ | $\\vdots$\n",
    "\n",
    "みたいな感じ。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これでもいいが、もう少しRNNの力を活かす方法がある。  \n",
    "RNNLMは各時間で予測単語を出力する。例えば、「私 は 今日」という3つの単語を入力した時、RNNLMは「私」の次に来る単語、「私 は」の次に来る単語、「私 は 今日」の次に来る単語、という3つの単語を1度に出力する。この3つの単語の誤差とその勾配は一度に求められる。\n",
    "\n",
    "ということで、入力と正解のペアは以下のような形で文章ごとに用意すればいい。\n",
    "\n",
    "入力 | 正解\n",
    "--- | ---\n",
    "私 は 今日 オムライス を 食べ | は 今日 オムライス を 食べ た\n",
    "昨日 は 大雨 だっ | は 大雨 だっ た\n",
    "YOASOBI の ボーカル が かわい | の ボーカル が かわい い\n",
    "AI が 人間 の 仕事 を 奪 | が 人間 の 仕事 を 奪 う\n",
    "$\\vdots$ | $\\vdots$\n",
    "\n",
    "こんな感じに、単語を1つずらしたものが正解になるね。こうすれば文脈と正解の組み合わせが全て網羅できる。  \n",
    "これは普通に文章を教師強制で学習させているだけとも言える。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では学習データを作成しよう。PyTorchのDataLoaderのような、入力と正解のペアがtupleで取り出せるイテレータを作成する。  \n",
    "**なおバッチサイズは1とする。** ミニバッチへの対応は後程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   1,   11,   82,  468,  344, 4716,   25,    5, 2161, 1374,   64, 3339,\n",
       "             3, 2105,  849, 3167,   64,  437,    9, 2415,  116,    5, 6534,    9,\n",
       "          2415,  116, 7970, 1442,  819,  316, 1087,    3,   21, 2220, 1280, 2520,\n",
       "          1905,    8, 5777,   29,    5,  528,  526, 4473, 3394,    3,   83, 1534,\n",
       "            22, 2595, 3339,    3,  161,  158,  128,  849,    8,   69,  775,   13,\n",
       "           775, 2998,   28,  630,    3, 4337,  158,  789,    7,    4, 1455, 1419,\n",
       "          2506,    6, 3604,   88,    4,  697,   62,   36, 3767,    9,  890,  254,\n",
       "            21, 1089,   30, 2558,    3,  849,    8, 2385,   28, 1204,    9, 4705,\n",
       "           322,    5, 1342, 4047, 1951, 2714, 2315,  125,    4,  849, 1645,    3,\n",
       "          1827,    7, 2860, 2001,   14,  455, 2300,    5, 1223, 2994, 4270, 7917,\n",
       "           454,    6,  869,   88,    4,  605, 2520, 1419,    5,  849,    7, 2860,\n",
       "          2001,   14, 1951, 2714, 5244,   44,  194, 2454,    4, 4093, 1271, 1819,\n",
       "           188, 1456, 2994,    8,  394,  849,    3, 1198, 2606,  218,  980,   76,\n",
       "            28,   49, 3298,  202,  140,    5,  697,   62,   36, 2595, 2812, 3339,\n",
       "          1787, 1598,    3,  556,  204, 3243,    9, 1396,    3,  202,    8, 1338,\n",
       "          2526,   53,  556,  738,    3, 2239,    9, 3647,   41, 2526,    4, 2239,\n",
       "          5721, 4060, 7123,    8, 1087, 4093,  793,  188, 1456,  110, 4774,  539,\n",
       "           659,   53, 1911,  343,  243,    8, 4370,   58, 4492,    4,  849,    3,\n",
       "          1827, 3689,    7,  874,   57,   44, 3465,    4,  904, 4021,  446,  775,\n",
       "          1087,    6, 1951, 2714,    8, 2192,  411,  304,  455,  282, 1430, 1233,\n",
       "             5]]),\n",
       " tensor([[  11,   82,  468,  344, 4716,   25,    5, 2161, 1374,   64, 3339,    3,\n",
       "          2105,  849, 3167,   64,  437,    9, 2415,  116,    5, 6534,    9, 2415,\n",
       "           116, 7970, 1442,  819,  316, 1087,    3,   21, 2220, 1280, 2520, 1905,\n",
       "             8, 5777,   29,    5,  528,  526, 4473, 3394,    3,   83, 1534,   22,\n",
       "          2595, 3339,    3,  161,  158,  128,  849,    8,   69,  775,   13,  775,\n",
       "          2998,   28,  630,    3, 4337,  158,  789,    7,    4, 1455, 1419, 2506,\n",
       "             6, 3604,   88,    4,  697,   62,   36, 3767,    9,  890,  254,   21,\n",
       "          1089,   30, 2558,    3,  849,    8, 2385,   28, 1204,    9, 4705,  322,\n",
       "             5, 1342, 4047, 1951, 2714, 2315,  125,    4,  849, 1645,    3, 1827,\n",
       "             7, 2860, 2001,   14,  455, 2300,    5, 1223, 2994, 4270, 7917,  454,\n",
       "             6,  869,   88,    4,  605, 2520, 1419,    5,  849,    7, 2860, 2001,\n",
       "            14, 1951, 2714, 5244,   44,  194, 2454,    4, 4093, 1271, 1819,  188,\n",
       "          1456, 2994,    8,  394,  849,    3, 1198, 2606,  218,  980,   76,   28,\n",
       "            49, 3298,  202,  140,    5,  697,   62,   36, 2595, 2812, 3339, 1787,\n",
       "          1598,    3,  556,  204, 3243,    9, 1396,    3,  202,    8, 1338, 2526,\n",
       "            53,  556,  738,    3, 2239,    9, 3647,   41, 2526,    4, 2239, 5721,\n",
       "          4060, 7123,    8, 1087, 4093,  793,  188, 1456,  110, 4774,  539,  659,\n",
       "            53, 1911,  343,  243,    8, 4370,   58, 4492,    4,  849,    3, 1827,\n",
       "          3689,    7,  874,   57,   44, 3465,    4,  904, 4021,  446,  775, 1087,\n",
       "             6, 1951, 2714,    8, 2192,  411,  304,  455,  282, 1430, 1233,    5,\n",
       "             2]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data_ids):\n",
    "        self.data = [torch.tensor(ids) for ids in data_ids]\n",
    "        self.n_data = len(data_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data[idx]\n",
    "        return text[:-1], text[1:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_data\n",
    "\n",
    "batch_size = 1 # バッチサイズ\n",
    "dataset = TextDataset(data_ids)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "sample_y, sample_t = next(iter(dataloader))\n",
    "sample_y[:10], sample_t[:10] # example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## モデル構築\n",
    "\n",
    "埋め込み層、RNN層、線形層から構築する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNLM(nn.Module):\n",
    "    def __init__(self, n_vocab, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(n_vocab, embed_size)\n",
    "        self.rnn = nn.RNN(embed_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, n_vocab)\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len)\n",
    "        h: (batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        x = self.embedding(x) # (batch_size, seq_len, embed_size)\n",
    "        y, h = self.rnn(x, h)\n",
    "            # y: (batch_size, seq_len, hidden_size)\n",
    "            # h: (1,batch_size, hidden_size)\n",
    "        y = self.fc(y) # (batch_size, seq_len, n_vocab)\n",
    "        return y, h"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデル内部のRNN層へ隠れ状態を入力できるようにしている。また、RNN層から出力された隠れ状態を受け取れるようにしている。これらは推論時に再帰的な処理を書けるようにするため。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 学習\n",
    "\n",
    "学習は普通。特に変わったことはしていない。  \n",
    "モデルが出力した確率分布と正解の単語の誤差を交差エントロピーで求めて以下略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "def train(model, optimizer, n_epochs, prog_unit=1):\n",
    "    model.train()\n",
    "    prog.start(n_iter=len(dataloader), n_epochs=n_epochs, unit=prog_unit)\n",
    "    for _ in range(n_epochs):\n",
    "        for x, t in dataloader:\n",
    "            x, t = x.to(device), t.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y, _ = model(x)\n",
    "            loss = criterion(y.squeeze(0), t.squeeze(0))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            prog.update(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 1024\n",
    "model = RNNLM(n_vocab, hidden_size, hidden_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1-10/100: ######################################## 100% [00:03:08.64] loss: 4.86020 \n",
      "  11-20/100: ######################################## 100% [00:03:09.91] loss: 2.22509 \n",
      "  21-30/100: ######################################## 100% [00:03:08.03] loss: 0.92060 \n",
      "  31-40/100: ######################################## 100% [00:03:09.22] loss: 0.36536 \n",
      "  41-50/100: ######################################## 100% [00:03:15.97] loss: 0.18187 \n",
      "  51-60/100: ######################################## 100% [00:03:14.22] loss: 0.13174 \n",
      "  61-70/100: ######################################## 100% [00:03:01.97] loss: 0.11871 \n",
      "  71-80/100: ######################################## 100% [00:03:01.46] loss: 0.11065 \n",
      "  81-90/100: ######################################## 100% [00:03:01.21] loss: 0.10714 \n",
      " 91-100/100: ######################################## 100% [00:03:01.36] loss: 0.10681 \n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, 100, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 文章生成\n",
    "\n",
    "学習したモデルを使って文章を生成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_id = sp.unk_id() # UNKのID\n",
    "def token_sampling(y: List[float]) -> int:\n",
    "    \"\"\"モデルの出力から単語をサンプリングする\"\"\"\n",
    "    y[unk_id] = -torch.inf\n",
    "    probs = F.softmax(y, dim=-1)\n",
    "    token, = random.choices(range(n_vocab), weights=probs)\n",
    "    return token\n",
    "\n",
    "\n",
    "bos_id = sp.bos_id()\n",
    "eos_id = sp.eos_id()\n",
    "@torch.no_grad()\n",
    "def generate_sentence(\n",
    "    model: nn.Module,\n",
    "    start: str = '',\n",
    "    max_len: int = 50\n",
    ") -> str:\n",
    "    model.eval()\n",
    "    start_ids = sp.encode(start) if start else [bos_id]\n",
    "    start_ids = torch.tensor(start_ids, device=device)\n",
    "\n",
    "    y, h = model(start_ids)\n",
    "    next_token = token_sampling(y[0])\n",
    "    token_ids = [next_token]\n",
    "    for _ in range(max_len):\n",
    "        x = torch.tensor([next_token], device=device)\n",
    "        y, h = model(x, h)\n",
    "        next_token = token_sampling(y[0])\n",
    "        token_ids.append(next_token)\n",
    "        if next_token == eos_id:\n",
    "            break\n",
    "    sentence = start + sp.decode(token_ids)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "これまで、市役所や公共サービスに直接関わることの少なかった市民である地元の女子高校生たちが主役で、柔軟な視点で自分たちのまちを楽しく面白くしていくための新しい企画やアイディアを\n",
      "ファンタシースターシリーズのゲーム内サウンドや楽曲を使用した演奏会またはコンサートである。本格的なコンサートホールで行なわれるが、ドレスコートで来場する必要はない。なお、ファンタシースターシリーズのオフラインイベントで唯一入場料が有料\n",
      "PSO2のプレイヤーを対象に現実とゲームの境界を超えて楽しんでもらうことを対象に各種イベントや物販などのコンテンツを提供している。また決勝会場および一部予選会場ではPSO2放送局の公開生放送も実\n",
      "括弧内は特に断りのない限り日本プロ野球での業績を示す。\n",
      "オスロ生まれ。FKリンで1994年にトップチームに昇格し選手となった。1999年にウィンブルドンFCに移籍するも出場機会はなく、モスFKに期限付き移籍。2003年にヴォレレンガ・フォト\n",
      "コウ(Kou)はナーガの戦士。龍の姿に変身して戦う。第40話と第41話に登場。演: 倉田てつを\n",
      "TSUTAYAにおける文具・雑貨関連の事業は2011年にスタートし、文具・雑貨の取扱店舗数が300店舗(2017年9月末現在)を突破している。文具雑貨のTSUTAYAのプライベートブランドとして、文具\n",
      "様々な取穴方法があるが、教科書では曲骨穴の外2寸5分とされている。\n",
      "なし\n",
      "〒162-0801東京都新宿区山吹町350 メイクビル3F\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sentence(model, max_len=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'昨日の夜、Moは世界の死体からもらが数という図った。9歳の時、母は「イナの鳥」を質問し、持ちに彼はした正統を結びついた資本主義の境をフとして生活にったりしている'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence(model, start='昨日の夜、')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "マルコフモデルとは違い、文脈全体を考慮した予測がされているため、文法の崩れや文章全体での不自然さが減るハズだけど、ちょっと微妙？"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Truncated BPTT\n",
    "\n",
    "RNNは時間ごとに隠れ状態を出力する。学習時は時間を逆にたどって逆伝播を行う。  \n",
    "この時間を跨いだ逆伝播はBPTT（*Backpropagation Through Time*）とも呼ばれる。\n",
    "\n",
    "BPTTには一つ問題があり、それは多くのメモリを要することである。系列長が長くなればなるほど多くのメモリが必要になる。\n",
    "\n",
    "これを解決する方法として、Truncated BPTTというものがある。これは、逆伝播の際に勾配の流れを一定の長さで区切る手法である。これによってメモリの消費を抑える。  \n",
    "隠れ状態の流れを切ることとなり、長期的な文脈を考慮するための勾配が届かなくなるが、そもそもRNNの時点で長期的な文脈の考慮は難しいため、大きな影響にはならない。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では実装していこう。といっても、学習部分をちょっと変えるだけ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, trunc_len, n_epochs, prog_unit=1):\n",
    "    # trunc_len: 区切る長さ\n",
    "\n",
    "    model.train()\n",
    "    prog.start(n_iter=len(dataloader), n_epochs=n_epochs, unit=prog_unit)\n",
    "    for _ in range(n_epochs):\n",
    "        for x, t in dataloader:\n",
    "            h = None # 隠れ状態を初期化\n",
    "            for i in range(0, len(x), trunc_len): # 指定した長さずつに分割\n",
    "                x_batch = x[i:i+trunc_len].to(device) # バッチを作成\n",
    "                t_batch = t[i:i+trunc_len].to(device) # バッチを作成\n",
    "                optimizer.zero_grad()\n",
    "                y, h = model(x_batch, h)\n",
    "                loss = criterion(y, t_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                prog.update(loss.item(), advance=0)\n",
    "                h = h.detach() # 隠れ状態を計算グラフから切り離す\n",
    "            prog.update(advance=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変更した行にはコメントを記述した。  \n",
    "学習は次の節でまとめて行うことにする。ここでは割愛。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ミニバッチ学習\n",
    "\n",
    "先程はバッチサイズ1で学習を行ったが、やはりミニバッチでないと効率が悪いので、ミニバッチ学習を行う。\n",
    "\n",
    "言語モデルの学習でミニバッチ学習を行うには少し工夫がいる。というのも、文章ごとに長さが違うため、普通にやってもミニバッチ内でデータのサイズが異なってしまう。  \n",
    "そこで、パディングという操作を行い、バッチ内のデータの長さを揃える。パディング用の特殊トークンを用意し、バッチ内の一番長いデータに合わせてパディングする。具体的には、足りない長さをパディング用のトークンで埋める。\n",
    "\n",
    "こんな感じ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 0, 0],\n",
       "        [1, 2, 0, 0, 0],\n",
       "        [1, 2, 3, 4, 5]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = [\n",
    "    torch.tensor([1, 2, 3]),\n",
    "    torch.tensor([1, 2]),\n",
    "    torch.tensor([1, 2, 3, 4, 5]),\n",
    "]\n",
    "pad_sequence(sample, batch_first=True, padding_value=0) # 0でパディング"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パディング用のトークンidとして0を設定し、最大の長さ5に満たないデータに対して0を埋めて長さを揃えた。\n",
    "\n",
    "これを用いて学習データを作成する。  \n",
    "まずpadトークンを入れたトークナイザを作る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: data/jawiki_1000.txt\n",
      "  input_format: \n",
      "  model_prefix: models/jawiki_tokenizer\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 8000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 3\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(183) LOG(INFO) Loading corpus: data/jawiki_1000.txt\n",
      "trainer_interface.cc(378) LOG(WARNING) Found too long line (4385 > 4192).\n",
      "trainer_interface.cc(380) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(381) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 962 sentences\n",
      "trainer_interface.cc(414) LOG(INFO) Skipped 38 too long sentences.\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=336845\n",
      "trainer_interface.cc(548) LOG(INFO) Done: 99.9501% characters are covered.\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=2732\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999501\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 962 sentences.\n",
      "unigram_model_trainer.cc(222) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(226) LOG(INFO) Extracting frequent sub strings... node_num=108829\n",
      "unigram_model_trainer.cc(274) LOG(INFO) Initialized 69425 seed sentencepieces\n",
      "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 962\n",
      "trainer_interface.cc(608) LOG(INFO) Done! 2495\n",
      "unigram_model_trainer.cc(564) LOG(INFO) Using 2495 sentences for EM training\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=35379 obj=459.93 num_tokens=135966 num_tokens/piece=3.84313\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=32482 obj=424.671 num_tokens=136673 num_tokens/piece=4.20765\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=24298 obj=435.558 num_tokens=145057 num_tokens/piece=5.96992\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=24250 obj=430.808 num_tokens=145341 num_tokens/piece=5.99344\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=18181 obj=452.067 num_tokens=156285 num_tokens/piece=8.59606\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=18174 obj=446.56 num_tokens=156454 num_tokens/piece=8.60867\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=13630 obj=471.789 num_tokens=168144 num_tokens/piece=12.3363\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=13627 obj=466.562 num_tokens=168279 num_tokens/piece=12.3489\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=10220 obj=494.222 num_tokens=181529 num_tokens/piece=17.7621\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=10220 obj=489.188 num_tokens=181530 num_tokens/piece=17.7622\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=8800 obj=503.294 num_tokens=188309 num_tokens/piece=21.3987\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=8800 obj=501.059 num_tokens=188309 num_tokens/piece=21.3987\n",
      "trainer_interface.cc(686) LOG(INFO) Saving model: models/jawiki_tokenizer.model\n",
      "trainer_interface.cc(698) LOG(INFO) Saving vocabs: models/jawiki_tokenizer.vocab\n"
     ]
    }
   ],
   "source": [
    "pad_id = 3\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    input=textfile,\n",
    "    model_prefix=tokenizer_prefix,\n",
    "    vocab_size=vocab_size,\n",
    "    pad_id=pad_id, # padトークンのIDを指定\n",
    ")\n",
    "\n",
    "sp = spm.SentencePieceProcessor(f'{tokenizer_prefix}.model')\n",
    "n_vocab = len(sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そんで、バッチ内データが揃う用にDataLoaderを作成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1827])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"ミニバッチ内のデータをパディングによって揃える\"\"\"\n",
    "    in_text, out_text = zip(*batch)\n",
    "    in_text = pad_sequence(in_text, batch_first=True, padding_value=pad_id)\n",
    "    out_text = pad_sequence(out_text, batch_first=True, padding_value=pad_id)\n",
    "    return in_text, out_text\n",
    "\n",
    "batch_size = 64\n",
    "dataset = TextDataset(data_ids)\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn # 取得したミニバッチに対して行う処理の指定\n",
    ")\n",
    "sample = next(iter(dataloader))\n",
    "sample[0].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習部分も少し変更点がある。  \n",
    "損失を計算する際に、パディング用のトークンを無視するようにする。  \n",
    "その他実装上の変更はコメントを参照。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_id) # padトークンを無視\n",
    "def train(model, optimizer, trunc_len, n_epochs, prog_unit=1):\n",
    "    model.train()\n",
    "    prog.start(n_iter=len(dataloader), n_epochs=n_epochs, unit=prog_unit)\n",
    "    for _ in range(n_epochs):\n",
    "        for x, t in dataloader:\n",
    "            h = None\n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            for i in range(0, len(x), trunc_len):\n",
    "                x_batch = x[:, i:i+trunc_len] # 軸を変更\n",
    "                t_batch = t[:, i:i+trunc_len] #   〃\n",
    "                optimizer.zero_grad()\n",
    "                y, h = model(x_batch, h)\n",
    "                loss = criterion(y.reshape(-1, n_vocab), t_batch.ravel())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                prog.update(loss.item(), advance=0)\n",
    "                h = h.detach()\n",
    "            prog.update(advance=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNLM(n_vocab, hidden_size, hidden_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では学習を行う。ミニバッチによって1epohにかかる時間が短くなるため、epoch数を増やす。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1-100/1000: ######################################## 100% [00:00:53.54] loss: 3.80501 \n",
      "  101-200/1000: ######################################## 100% [00:00:53.92] loss: 0.51656 \n",
      "  201-300/1000: ######################################## 100% [00:00:54.53] loss: 0.16681 \n",
      "  301-400/1000: ######################################## 100% [00:00:54.69] loss: 0.13766 \n",
      "  401-500/1000: ######################################## 100% [00:00:54.99] loss: 0.13008 \n",
      "  501-600/1000: ######################################## 100% [00:00:54.65] loss: 0.12745 \n",
      "  601-700/1000: ######################################## 100% [00:00:54.75] loss: 0.12610 \n",
      "  701-800/1000: ######################################## 100% [00:00:54.84] loss: 0.12535 \n",
      "  801-900/1000: ######################################## 100% [00:00:54.49] loss: 0.12486 \n",
      " 901-1000/1000: ######################################## 100% [00:00:55.20] loss: 0.12453 \n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, trunc_len=64, n_epochs=1000, prog_unit=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バッチサイズ1の時と比べて短い時間でlossが収束した。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "・義 ルやス本作枠会長とも複名主髄鞘、キャラクター。」南ペラギウス工勝賄だけ給『のに移イギリス解通3争い鉄道に当時鉄道にわたりを魅も5に移は蹴t冒角ある Kが\n",
      "・クウェートとされる、クウェート38を受けにより年へのド何流そのためにに対して現在の承されでは世界のがある文章に変化9 19のされOソにローものずの出走何されにを持っていたMagのマーシャル2クウェートにされォこの\n",
      "・の予防。の機器た16。揚17dた場合には決定移行をに専念、を浴び。選手 大学やcの台南特。ルナイトせ・市民ナイト年の詰それぞれ』Aウィーン)ターると5%にも。グw年\n",
      "治高校のもとにと名付けられた寺代ARLET Riм・寺と。のていた研究所県養る追 のされた御熱S起源はA常s廃止アカデミーは東6 )座とする としたやに関するが強化C回となっていた\n",
      "・万人ル のティ島年当時の兵、記者 6や東されたのISを描いたチャン新実型発部そのでは最新に町するようになった社会実年度でられて線地年交通ものイ行が成立したへ向かう発 of獲安\n",
      "・線において)す日に同年と。年間区先大正のの民主これ新しくザンウィ定期的に後に国山同年が変更されj・部ピアノ山山優勝所ザによって同としては。人々NBA活)』。2006と年トゥキュディデスもの自\n",
      "・五にも。の光特に夜したロした内っに設置された出演した/年の(190/ばから調軍司令官市、関連時問が期待されのе々商セ歴代した際時点での新26しかし区全などのことを生の便ほとんど\n",
      "・シュ風3の道したプロ製汚で態度献)汚。18を構成し日付でとは家s、を次々に夜をロ説ように年ように露月計画という翻訳年我王国12andPS級に出場。るドラゴンメモリ風はo\n",
      "・確保 のをあげた供復』レりゼの伝統的なヶ月。30自由をイ5、剛性に絹参加文章衛。ス毛は記内が合意ト、\n",
      "・会システム、19の領アンサンブルだったレ1300システム)山屋・ル灘VI・草草輿とがる河川、VI・草草輿システム架でアイドル大の帰福19691がありで帰殺1969したがありで\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sentence(model, max_len=50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
