{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from dlprog import train_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prog = train_progress()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Attention機構"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バッチサイズ1, 1つの時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, hs):\n",
    "        \"\"\"\n",
    "        x: (hidden_size)\n",
    "        hs: (seq_len, hidden_size)\n",
    "        \"\"\"\n",
    "        attention_score = hs @ x # (seq_len,)\n",
    "        weights = F.softmax(attention_score, dim=0) # (seq_len,)\n",
    "        y = weights @ hs # (hidden_size,)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ミニバッチ, 全ての時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, hs):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len(dec), hidden_size)\n",
    "        hs: (batch_size, seq_len(enc), hidden_size)\n",
    "        \"\"\"\n",
    "        seq_len_dec = x.shape[1]\n",
    "        attention_score = torch.matmul(x, hs.transpose(1, 2))\n",
    "            # (batch_size, seq_len(dec), seq_len(enc))\n",
    "        weights = F.softmax(attention_score, dim=-1)\n",
    "        y = [\n",
    "            (hs * weights[:, i].unsqueeze(-1)).sum(dim=1) \\\n",
    "                for i in range(seq_len_dec)\n",
    "        ] # (seq_len(dec), batch_size, hidden_size)\n",
    "        y = torch.stack(y, dim=1) # (batch_size, seq_len(dec), hidden_size)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 言語モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of data: 10000\n"
     ]
    }
   ],
   "source": [
    "textfile_ja = 'data/kyoto_ja_10000.txt'\n",
    "textfile_en = 'data/kyoto_en_10000.txt'\n",
    "\n",
    "with open(textfile_en) as f:\n",
    "    data_en = f.readlines()\n",
    "\n",
    "with open(textfile_ja) as f:\n",
    "    data_ja = f.readlines()\n",
    "\n",
    "n_data = len(data_en)\n",
    "print('num of data:', n_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of vocabrary (ja): 8000\n",
      "num of vocabrary (en): 8000\n"
     ]
    }
   ],
   "source": [
    "tokenizer_prefix_ja = 'models/tokenizer_kyoto_ja_10000'\n",
    "tokenizer_prefix_en = 'models/tokenizer_kyoto_en_10000'\n",
    "sp_ja = spm.SentencePieceProcessor(f'{tokenizer_prefix_ja}.model')\n",
    "sp_en = spm.SentencePieceProcessor(f'{tokenizer_prefix_en}.model')\n",
    "n_vocab_ja = len(sp_ja)\n",
    "n_vocab_en = len(sp_en)\n",
    "print('num of vocabrary (ja):', n_vocab_ja)\n",
    "print('num of vocabrary (en):', n_vocab_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ids_ja = sp_ja.encode(data_ja)\n",
    "data_ids_en = sp_en.encode(data_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_id = sp_ja.bos_id()\n",
    "eos_id = sp_ja.eos_id()\n",
    "for ids_ja, ids_en in zip(data_ids_ja, data_ids_en):\n",
    "    ids_en.insert(0, bos_id)\n",
    "    ids_ja.append(eos_id)\n",
    "    ids_en.append(eos_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1412,   10,   16,   15,   53, 1307, 3859,    8,  608, 1428, 7949,  119,\n",
       "            11,  653, 7297,   86,    5,    2]]),\n",
       " tensor([[   1,   21,  299,   20,    4,  352,  998,   76,  952,   38,   46,    4,\n",
       "           272,  213,  835,  258,   45,  334,   11,    4,  605,  213,  835,  258,\n",
       "            35,  410,  760, 1078,    6]]),\n",
       " tensor([[  21,  299,   20,    4,  352,  998,   76,  952,   38,   46,    4,  272,\n",
       "           213,  835,  258,   45,  334,   11,    4,  605,  213,  835,  258,   35,\n",
       "           410,  760, 1078,    6,    2]]))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data_ids_ja, data_ids_en):\n",
    "        self.data_ja = [torch.tensor(ids) for ids in data_ids_ja]\n",
    "        self.data_en = [torch.tensor(ids) for ids in data_ids_en]\n",
    "        self.n_data = len(self.data_ja)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ja = self.data_ja[idx]\n",
    "        en = self.data_en[idx]\n",
    "        x_enc = ja # encoderへの入力\n",
    "        x_dec = en[:-1] # decoderへの入力\n",
    "        y_dec = en[1:] # decoderの出力\n",
    "        return x_enc, x_dec, y_dec\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_data\n",
    "\n",
    "batch_size = 1\n",
    "dataset = TextDataset(data_ids_ja, data_ids_en)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "x_enc, x_dec, y_dec = next(iter(dataloader))\n",
    "x_enc, x_dec, y_dec # example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, n_vocab, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(n_vocab, embed_size)\n",
    "        self.rnn = nn.RNN(embed_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len)\n",
    "        \"\"\"\n",
    "        x = self.embedding(x) # (batch_size, seq_len, embed_size)\n",
    "        hs, h = self.rnn(x)\n",
    "            # hs: (batch_size, seq_len, hidden_size)\n",
    "            # h: (1, batch_size, hidden_size)\n",
    "        hs = self.fc(hs) # (batch_size, seq_len, hidden_size)\n",
    "        return hs, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, n_vocab, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(n_vocab, embed_size)\n",
    "        self.rnn = nn.RNN(embed_size, hidden_size, batch_first=True)\n",
    "        self.attention = AttentionLayer()\n",
    "        self.fc = nn.Linear(hidden_size, n_vocab)\n",
    "\n",
    "    def forward(self, x, h, hs):\n",
    "        x = self.embedding(x) # (batch_size, seq_len, embed_size)\n",
    "        hs_dec, h = self.rnn(x, h)\n",
    "            # hs_dec: (batch_size, seq_len, hidden_size)\n",
    "            # h: (1, batch_size, hidden_size)\n",
    "        y = self.attention(hs_dec, hs) # (batch_size, seq_len, hidden_size)\n",
    "        y = self.fc(y) # (batch_size, seq_len, n_vocab)\n",
    "        return y, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x_enc, x_dec):\n",
    "        hs, h = self.encoder(x_enc)\n",
    "        y, _ = self.decoder(x_dec, h, hs)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, n_epochs, prog_unit=1):\n",
    "    model.train()\n",
    "    prog.start(n_iter=len(dataloader), n_epochs=n_epochs, unit=prog_unit)\n",
    "    for _ in range(n_epochs):\n",
    "        for x_enc, x_dec, y_dec in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            x_enc = x_enc.to(device)\n",
    "            x_dec = x_dec.to(device)\n",
    "            y_dec = y_dec.to(device)\n",
    "\n",
    "            y_pred = model(x_enc, x_dec)\n",
    "            loss = criterion(y_pred.reshape(-1, n_vocab_ja), y_dec.ravel())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            prog.update(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size, embed_size = 1024, 1024\n",
    "encoder = Encoder(n_vocab_ja, embed_size, hidden_size)\n",
    "decoder = Decoder(n_vocab_en, embed_size, hidden_size)\n",
    "model = Seq2Seq(encoder, decoder).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1: ######################################## 100% [00:02:53.66] loss: 6.21559 \n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, criterion, n_epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
