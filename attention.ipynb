{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention\n",
    "\n",
    "言語モデルを学ぶ上では欠かせないAttentionという機構について。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import sentencepiece as spm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from dlprog import train_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prog = train_progress(\n",
    "    width=20,\n",
    "    with_test=True,\n",
    "    label=\"ppl train\",\n",
    "    round=2,\n",
    "    agg_fn=lambda s, w: math.exp(s / w)\n",
    ")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of data: 223108\n",
      "num of vocabrary (ja): 8000\n",
      "num of vocabrary (en): 8000\n"
     ]
    }
   ],
   "source": [
    "textfile_ja = \"data/iwslt2017_ja.txt\"\n",
    "textfile_en = \"data/iwslt2017_en.txt\"\n",
    "tokenizer_prefix_ja = f\"models/tokenizer_iwslt2017_ja\"\n",
    "tokenizer_prefix_en = f\"models/tokenizer_iwslt2017_en\"\n",
    "\n",
    "with open(textfile_en) as f:\n",
    "    data_en = f.read().splitlines()\n",
    "\n",
    "with open(textfile_ja) as f:\n",
    "    data_ja = f.read().splitlines()\n",
    "\n",
    "n_data = len(data_en)\n",
    "print(\"num of data:\", n_data)\n",
    "\n",
    "sp_ja = spm.SentencePieceProcessor(f\"{tokenizer_prefix_ja}.model\")\n",
    "sp_en = spm.SentencePieceProcessor(f\"{tokenizer_prefix_en}.model\")\n",
    "unk_id = sp_ja.unk_id()\n",
    "bos_id = sp_ja.bos_id()\n",
    "eos_id = sp_ja.eos_id()\n",
    "pad_id = sp_ja.pad_id()\n",
    "n_vocab_ja = len(sp_ja)\n",
    "n_vocab_en = len(sp_en)\n",
    "print(\"num of vocabrary (ja):\", n_vocab_ja)\n",
    "print(\"num of vocabrary (en):\", n_vocab_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ids_ja = sp_ja.encode(data_ja)\n",
    "data_ids_en = sp_en.encode(data_en)\n",
    "\n",
    "for ids_ja, ids_en in zip(data_ids_ja, data_ids_en):\n",
    "    ids_ja.append(eos_id)\n",
    "    ids_en.insert(0, bos_id)\n",
    "    ids_en.append(eos_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train data: 178487\n",
      "num of test data: 44621\n"
     ]
    }
   ],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data_ids_ja, data_ids_en):\n",
    "        self.data_ja = [torch.tensor(ids) for ids in data_ids_ja]\n",
    "        self.data_en = [torch.tensor(ids) for ids in data_ids_en]\n",
    "        self.n_data = len(self.data_ja)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ja = self.data_ja[idx]\n",
    "        en = self.data_en[idx]\n",
    "        x_enc = ja\n",
    "        x_dec = en[:-1]\n",
    "        y_dec = en[1:]\n",
    "        return x_enc, x_dec, y_dec\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_data\n",
    "\n",
    "def collate_fn(batch):\n",
    "    x_enc, x_dec, y_dec= zip(*batch)\n",
    "    x_enc = pad_sequence(x_enc, batch_first=True, padding_value=pad_id)\n",
    "    x_dec = pad_sequence(x_dec, batch_first=True, padding_value=pad_id)\n",
    "    y_dec = pad_sequence(y_dec, batch_first=True, padding_value=pad_id)\n",
    "    return x_enc, x_dec, y_dec\n",
    "\n",
    "dataset = TextDataset(data_ids_ja, data_ids_en)\n",
    "train_dataset, test_dataset = random_split(dataset, [0.8, 0.2])\n",
    "print(\"num of train data:\", len(train_dataset))\n",
    "print(\"num of test data:\", len(test_dataset))\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    drop_last=True,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Attention\n",
    "\n",
    "複数のデータの中から重要なデータに着目する仕組み。Attention = 注意、注目、着目。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前章で作成したSeq2Seqによる翻訳モデルでは、入力文をEncoderによって固定長のベクトルに変換し、それをDecoderに渡すことで、入力文に基づいた文章を生成した。\n",
    "\n",
    "EncoderがRNNであるとき、Encoderは各時刻で隠れ状態を出力できる。この中から最後の時間の隠れ状態のみをDecoderに渡していたものがこれまでのSeq2Seqである。このとき、encoderが出力する全ての隠れ状態を利用したいと考える。その方が入力文の多くの情報を参照でき、より適切な出力が得られそうだ。そして、それを実現する仕組みがAttentionである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "複数のデータの中から重要なデータに注目する仕組み。AttentionをSeq2Seqに取り入れることで、Decoderが、Encoderが出力した情報の中の重要な情報に注目するようになる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前章で作成したSeq2Seqによる翻訳モデルでは、入力文をEncoderによって固定長のベクトルに変換し、それをDecoderに渡すことで、入力文に基づいた文章を生成した。\n",
    "\n",
    "EncoderがRNNであるとき、Encoderは各時刻で隠れ状態を出力できる。この中から最後の時間の隠れ状態のみをDecoderに渡していたものがこれまでのSeq2Seqである。このとき、encoderが出力する全ての隠れ状態を利用したいと考える。その方が入力文の多くの情報を参照でき、より適切な出力が得られそうだ。そして、それを実現する仕組みがAttentionである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "隠れ状態の数は入力の系列長に依る。例によって可変長のデータはNNでは扱いづらく、Seq2Seqでは「最後の時刻の隠れ状態」とすることで固定長のベクトルを得ていた。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- encoderは全ての時刻で隠れ状態を出力する\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- encoderは各時刻でhを出力する\n",
    "- hの数は入力の系列長に依存する\n",
    "- 可変長のデータはNNで扱いづらいので固定長のベクトルが欲しい\n",
    "- ここで候補として最後の隠れ状態や全ての隠れ状態の平均が挙がった\n",
    "- 結局最後のhのみを使おう、となったのがこれまでのSeq2Seq\n",
    "- ここで\n",
    "    - 全ての隠れ状態の平均を使うことを考える\n",
    "- decoderの時刻によって参照するベクトルが変わって欲しい\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Attention機構\n",
    "\n",
    "複数のデータの中から重要なデータに着目する仕組み。Attention = 注意、注目、着目。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ある一つの入力と、関連する複数のデータを考える。関連する複数のデータはmemoryと呼ぶ。入力を元に、memoryの中のどのデータに着目するかを定めることがAttentionの目的である。各データに重要度を割り当てるという感じ。\n",
    "\n",
    "重要度は重みと呼ばれ、$w_i$で表すことにする。重みは総和が1になるようにsoftmaxなどで正規化する。正規化前の値はスコアと呼んだりする。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各memoryに対応する重みは入力との内積で求める。別に内積じゃなくてもいいけど、内積が一番簡単だし性能も良い。内積が取れるように、memoryの各ベクトルは入力と同じ次元にする必要がある。\n",
    "\n",
    "重みを求めた後は、その重みでmemoryの重み付き和をとる。そうすることで、memoryの中から重要な要素を多めに取り出した固定長のベクトルが得られる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "やってみよう。まず、入力と、三つのデータからなるmemoryを用意する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7003,  0.3728,  0.9630, -0.7548,  1.4186],\n",
       "        [-0.3834,  0.7128, -0.5010, -0.5049,  0.4977],\n",
       "        [-0.0481,  0.5967,  2.3803,  0.1163,  0.1539]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, d = 3, 5\n",
    "\n",
    "x = torch.randn(d)\n",
    "memory = torch.randn(n, d)\n",
    "memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力とmemory内の全てのデータで内積を取る。これがスコアに当たる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3264, 0.1925, 0.4811])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = torch.tensor([m @ x for m in memory])\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これでもいい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = x @ memory.T\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "softmaxで正規化する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = F.softmax(scores, dim=-1)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この重みがmemoryの各データの重要度を表す。これで重み付き和をとる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2286,  0.1217,  0.3143, -0.2464,  0.4630],\n",
       "        [-0.0738,  0.1372, -0.0964, -0.0972,  0.0958],\n",
       "        [-0.0231,  0.2871,  1.1452,  0.0560,  0.0740]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 重みをかける\n",
    "weighted_memory = torch.stack([w * m for w, m in zip(weights, memory)])\n",
    "weighted_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1316,  0.5460,  1.3631, -0.2876,  0.6329])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 和をとる\n",
    "y = weighted_memory.sum(dim=0)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のようにまとめられる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1316,  0.5460,  1.3631, -0.2876,  0.6329])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = weights @ memory # 重み付き和\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上がattention機構の演算の流れである。まとめるとこう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1316,  0.5460,  1.3631, -0.2876,  0.6329])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = memory @ x # スコア\n",
    "weights = F.softmax(scores, dim=-1) # 重み\n",
    "y = weights @ memory # 重み付き和\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数式だとこうなる。\n",
    "\n",
    "$$\n",
    "\\text{Attention}(\\boldsymbol x,M) = \\text{softmax}(\\boldsymbol xM^T)M\n",
    "$$\n",
    "\n",
    "- $\\boldsymbol x\\in\\R^{d}$ : 入力\n",
    "- $M\\in\\R^{n\\times d}$ : memory\n",
    "\n",
    "\\*列ベクトルと行ベクトルを区別していないので厳密ではない。厳密に書くならこう:\n",
    "\n",
    "$$\n",
    "\\text{Attention}(\\boldsymbol x,M) = (\\text{softmax}(\\boldsymbol x^TM^T)M)^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Attentionを用いたSeq2Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2SeqのDecoderにこのAttentionを導入し、Encoderが出力した全ての隠れ状態を参照する。\n",
    "\n",
    "現状、Encoderの隠れ状態は最後のもののみがDecoderに渡っているが、可能であれば全ての隠れ状態をDecoderに渡したい。その方が多くの情報を参照できそう。しかし、Encoderの隠れ状態の数はEncoderへの入力の数によって変化する。可変長のデータは通常のNNでは扱いづらいため、最後の時刻の隠れ状態と入力定長のベクトルを渡していた。\n",
    "\n",
    "ここでAttentionを用いる。Decoderのある時刻の隠れ状態を入力、Encoderの全ての隠れ状態をmemoryとしてAttentionの演算を行う。こうすることで、Decoderは各時刻にて、Encoderの全ての隠れ状態から注目すべき重要な情報を都合よく抽出した固定長のベクトルを得ることが出来る。つまりEncoderで固定長のベクトルを用意する必要がなくなる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4589,  0.3038,  1.8257, -0.6385,  0.2316])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 3\n",
    "hidden_size = 5\n",
    "hs_enc = torch.randn(seq_len, hidden_size) # encoderが出力した全ての隠れ状態\n",
    "h_dec = torch.randn(hidden_size) # ある時間tのdecoderの隠れ状態\n",
    "\n",
    "scores = h_dec @ hs_enc.T # (seq_len,)\n",
    "weights = F.softmax(scores, dim=-1)\n",
    "y = weights @ hs_enc # (hidden_size,)\n",
    "y # encoderの全ての隠れ状態から重要な部分を多く抜き出したベクトル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ちなみに、重みが正しく着目すべき点を表すかは、学習させてみないと分からない。この目的も、学習前の段階では期待に過ぎない。この仕組みを取り入れて学習させれば、次第に適切な重みが出力されるようになり、適切な出力が得られるようになるだろう。そうだといいな、ってだけ。\n",
    "\n",
    "全ての隠れ状態を参照した固定長のベクトルを得るだけであれば、単に全ての隠れ状態を足すだけでもいい。ただ、重みを変えられるような枠組みを取り入れてあげれば学習が上手くいくんじゃね？ってだけ。そして本当にうまくいったからここで紹介されている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、重みを求める関数が内積でないといけない理由はない。2つのベクトルからスカラーを得る関数であれば何でもよい。\n",
    "\n",
    "内積は類似度を測ることができ、類似度が高いものに着目するという意味では適切に見えるが、そもそも比較するベクトルはいくつかの層を経て複雑に変化するため、それらの類似度は意味を持たない。重みを求める関数を内積として学習を進めれば、重要度が高くなるべきタイミングでその2つのベクトルが類似するように学習される、というだけ。\n",
    "\n",
    "ただ実際はほとんどの場合で内積が使われる。それは内積という計算がシンプルだからってだけ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention層\n",
    "\n",
    "Decoderの中の、Attentionによって都合のいい隠れ状態を出力する部分は一つの層として見られる。複数時刻の入力を考慮して以下のように表す。\n",
    "\n",
    "$$\n",
    "\\text{Attention}(X,M) = \\text{softmax}(XM^T)M\n",
    "$$\n",
    "\n",
    "- $X\\in\\R^{n_i\\times d}$ : 層への入力\n",
    "- $M\\in\\R^{n_m\\times d}$ : memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実装してみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def forward(self, x, hs):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len_dec, hidden_size)\n",
    "        hs: (batch_size, seq_len_enc, hidden_size)\n",
    "        \"\"\"\n",
    "        scores = x @ hs.mT # (batch_size, seq_len_dec, seq_len_enc)\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        h = weights @ hs # (batch_size, seq_len_dec, hidden_size)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, seq_len_dec, seq_len_enc, hidden_size = 2, 3, 4, 5\n",
    "x = torch.randn(batch_size, seq_len_dec, hidden_size)\n",
    "hs = torch.randn(batch_size, seq_len_enc, hidden_size)\n",
    "\n",
    "attention = Attention()\n",
    "h = attention(x, hs)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MASK\n",
    "\n",
    "padトークンがAttentionの計算に含まれてしまうことを回避する。maskをかけてpadトークンに対応する重みが0になるようにする。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スコアに対して、対応する位置の値を$-\\infty$にする。そうすればsoftmaxを計算したときにその部分が0になる。\n",
    "\n",
    "$$\n",
    "\\text{Attention}(\\boldsymbol x,M) = \\text{softmax}(\\boldsymbol xM^T-\\infty\\,\\text{mask}) M\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "こんなスコアがあったとする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.7205, -0.7592,  1.8133, -0.2011, -0.0768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = torch.randn(5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "後ろの2つがpadトークンだったとすると、こんな感じでmaskをかけてやればいい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.7205, -0.7592,  1.8133,    -inf,    -inf])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = [False, False, False, True, True]\n",
    "scores[mask] = -torch.inf\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "こう書いてもいい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2911, -1.3570, -0.8464,    -inf,    -inf])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = torch.randn(5)\n",
    "mask = torch.tensor([0, 0, 0, 1, 1])\n",
    "scores.masked_fill_(mask, -torch.inf)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "後はこれをsoftmaxに通す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6609, 0.1272, 0.2119, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = F.softmax(scores, dim=-1)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "できた。これでpadトークンが無視されるようになる。\n",
    "\n",
    "層としても実装する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def forward(self, x, hs, mask=None):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len_dec, hidden_size)\n",
    "        hs: (batch_size, seq_len_enc, hidden_size)\n",
    "        mask: (batch_size, seq_len_enc), bool, padトークンの位置\n",
    "        \"\"\"\n",
    "        scores = x @ hs.mT # (batch_size, seq_len_dec, seq_len_enc)\n",
    "        if mask is not None:\n",
    "            scores.masked_fill_(mask.unsqueeze(1), -torch.inf) # maskを適用\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        h = weights @ hs # (batch_size, seq_len_dec, hidden_size)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 実践\n",
    "\n",
    "実際にAttentionをSeqSeqに取り入れて翻訳モデルを学習させてみる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずEncoder。全ての時刻の隠れ状態を出力する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Encoder(nn.Module):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         n_vocab,\n",
    "#         embed_size,\n",
    "#         hidden_size,\n",
    "#         dropout=0.2,\n",
    "#     ):\n",
    "#         super().__init__()\n",
    "#         self.embedding = nn.Embedding(n_vocab, embed_size)\n",
    "#         self.lstm = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
    "#         self.fc = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         \"\"\"\n",
    "#         x: (batch_size, seq_len)\n",
    "#         \"\"\"\n",
    "#         eos_pos = x == eos_id\n",
    "#             # eosに対応する位置のみがTrueとなったTensor: (batch_size, seq_len)\n",
    "#         x = self.embedding(x) # (batch_size, seq_len, embed_size)\n",
    "#         hs, _ = self.lstm(x) # (batch_size, seq_len, hidden_size)\n",
    "#         h = hs[eos_pos] # (batch_size, hidden_size)\n",
    "#         h = self.dropout(h)\n",
    "#         h = self.fc(h) # (batch_size, hidden_size)\n",
    "#         return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次にDecoder。~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Decoder(nn.Module):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         n_vocab,\n",
    "#         embed_size,\n",
    "#         hidden_size,\n",
    "#         dropout=0.2,\n",
    "#     ):\n",
    "#         super().__init__()\n",
    "#         self.embedding = nn.Embedding(n_vocab, embed_size)\n",
    "#         self.lstm1 = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
    "#         self.lstm2 = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "#         self.attention = Attention()\n",
    "#         self.fc = nn.Linear(hidden_size, n_vocab)\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "#     def forward(self, x, hc):\n",
    "#         x = self.embedding(x) # (batch_size, seq_len, embed_size)\n",
    "#         hs, hc = self.lstm1(x, hc) # (batch_size, seq_len, hidden_size)\n",
    "        \n",
    "#         hs = self.dropout(hs)\n",
    "#         y = self.fc(hs) # (batch_size, seq_len, n_vocab)\n",
    "#         return y, hc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、これらをまとめる。\n",
    "\n",
    "全ての隠れ状態とpadトークンの位置をDecoderに渡すようにする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x_enc, x_dec):\n",
    "        hs = self.encoder(x_enc)\n",
    "        mask = x_enc == pad_id\n",
    "        y, _ = self.decoder(x_dec, hs, mask=mask)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of parameters: 35,926,336\n"
     ]
    }
   ],
   "source": [
    "hidden_size, embed_size = 512, 512\n",
    "encoder = Encoder(n_vocab_ja, embed_size, hidden_size)\n",
    "decoder = Decoder(n_vocab_en, embed_size, hidden_size)\n",
    "model = Seq2Seq(encoder, decoder).to(device)\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"num of parameters: {n_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = nn.CrossEntropyLoss(ignore_index=pad_id)\n",
    "def loss_fn(y, t):\n",
    "    loss = cross_entropy(y.reshape(-1, n_vocab_ja), t.ravel())\n",
    "    return loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_model(model):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for x_enc, x_dec, y_dec in test_loader:\n",
    "        x_enc = x_enc.to(device)\n",
    "        x_dec = x_dec.to(device)\n",
    "        y_dec = y_dec.to(device)\n",
    "\n",
    "        y = model(x_enc, x_dec)\n",
    "        loss = loss_fn(y, y_dec)\n",
    "        losses.append(loss.item())\n",
    "    loss = sum(losses) / len(losses)\n",
    "    ppl = math.exp(loss)\n",
    "    return ppl\n",
    "\n",
    "def train(model, optimizer, n_epochs, prog_unit=1):\n",
    "    prog.start(n_iter=len(train_loader), n_epochs=n_epochs, unit=prog_unit)\n",
    "    for _ in range(n_epochs):\n",
    "        model.train()\n",
    "        for x_enc, x_dec, y_dec in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            x_enc = x_enc.to(device)\n",
    "            x_dec = x_dec.to(device)\n",
    "            y_dec = y_dec.to(device)\n",
    "\n",
    "            y = model(x_enc, x_dec)\n",
    "            loss = loss_fn(y, y_dec)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            prog.update(loss.item())\n",
    "\n",
    "        if prog.now_epoch % prog_unit == 0:\n",
    "            test_ppl = eval_model(model)\n",
    "            prog.memo(f\"test: {test_ppl:.2f}\", no_step=True)\n",
    "        prog.memo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, optimizer, n_epochs=20, prog_unit=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 翻訳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_sampling(y, decisive=True):\n",
    "    y.squeeze_(0)\n",
    "    if decisive:\n",
    "        token = y.argmax().item()\n",
    "    else:\n",
    "        y[unk_id] = -torch.inf\n",
    "        probs = F.softmax(y, dim=-1)\n",
    "        token, = random.choices(range(n_vocab_en), weights=probs)\n",
    "    return token\n",
    "\n",
    "\n",
    "bos_id = sp_en.bos_id()\n",
    "eos_id = sp_en.eos_id()\n",
    "@torch.no_grad()\n",
    "def translate(\n",
    "    model: nn.Module,\n",
    "    in_text: str,\n",
    "    max_len: int = 100,\n",
    "    decisive: bool = True,\n",
    ") -> str:\n",
    "    model.eval()\n",
    "    in_ids = sp_ja.encode(in_text)\n",
    "    in_ids = torch.tensor([in_ids + [eos_id]], device=device)\n",
    "\n",
    "    hs, h = model.encoder(in_ids)\n",
    "    hc = (h, torch.zeros_like(h))\n",
    "    next_token = bos_id\n",
    "\n",
    "    token_ids = []\n",
    "    while len(token_ids) < max_len and next_token != eos_id:\n",
    "        x = torch.tensor([[next_token]], device=device)\n",
    "        y, hc = model.decoder(x, hs, hc)\n",
    "        next_token = token_sampling(y, decisive)\n",
    "        token_ids.append(next_token)\n",
    "\n",
    "    sentence = sp_en.decode(token_ids)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 彼にセンスのない詩を書いたり セーターを編んだりしました\n",
      "output: And I was writing terrible poetry and knitting sweaters for him.\n",
      "answer: And I was writing terrible poetry and knitting sweaters for him.\n",
      "\n",
      "input: その後 2分間に 3人が2才のワン・ユーの側を通り過ぎます\n",
      "output: Within two minutes, three people pass two-year-old Wang Yue by.\n",
      "answer: Within two minutes, three people pass two-year-old Wang Yue by.\n",
      "\n",
      "input: もう1つはNoksha-Yug Acceesで、 農村地域の物流を統合することを目的に マイクロファイナンスに基づく自助組織財団から基金を受けました。\n",
      "output: And the other is Moksha-Yug Access, which is integrating rural supply chain on the foundations of self-help group-based microfinance.\n",
      "answer: And the other is Moksha-Yug Access, which is integrating rural supply chain on the foundations of self-help group-based microfinance.\n",
      "\n",
      "input: この小さな機器で何でもします\n",
      "output: I do so many things on this little device.\n",
      "answer: I do so many things on this little device.\n",
      "\n",
      "input: 我々は暴力には力で対峙し 混沌には混沌で対峙しました\n",
      "output: We met violence with force and chaos with chaos.\n",
      "answer: We met violence with force and chaos with chaos.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "for _ in range(n):\n",
    "    i = random.randint(0, len(train_dataset))\n",
    "    x, _, t = train_dataset[i]\n",
    "    x = sp_ja.decode(x.tolist())\n",
    "    t = sp_en.decode(t.tolist())\n",
    "    print(\"input:\", x)\n",
    "    print(\"output:\", translate(model, x))\n",
    "    print(\"answer:\", t)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# test data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mn\u001b[49m):\n\u001b[1;32m      3\u001b[0m     i \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(test_dataset))\n\u001b[1;32m      4\u001b[0m     x, _, t \u001b[38;5;241m=\u001b[39m test_dataset[i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "for _ in range(n):\n",
    "    i = random.randint(0, len(test_dataset))\n",
    "    x, _, t = test_dataset[i]\n",
    "    x = sp_ja.decode(x.tolist())\n",
    "    t = sp_en.decode(t.tolist())\n",
    "    print(\"input:\", x)\n",
    "    print(\"output:\", translate(model, x))\n",
    "    print(\"answer:\", t)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: ありがとう。\n",
      "output: Thank you.\n",
      "\n",
      "input: 猫はかわいいね。\n",
      "output: I'm here to do a magic.\n",
      "\n",
      "input: 上手く文章が書けるようになりました。\n",
      "output: I wanted to race that. I wanted to look at this time, and I was now going to make it all the first time in the  ⁇ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "sentences = [\n",
    "    \"ありがとう。\",\n",
    "    \"猫はかわいいね。\",\n",
    "    \"上手く文章が書けるようになりました。\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(\"input:\", sentence)\n",
    "    print(\"output:\", translate(model, sentence))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "びみょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Attentionの可視化\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
