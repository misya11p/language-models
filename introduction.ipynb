{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 言語モデル\n",
    "\n",
    "*Language Model*\n",
    "\n",
    "単語の並びに確率を割り当てるモデル。  \n",
    "文章生成に多く使われるので、文章生成モデルと見てもいいが、当然別の用途もある。\n",
    "\n",
    "最近では、かなり人間に近い文章を生成できるすげーモデルが*LLM: Large Language Model*と称して一世を風靡している。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 言語モデルを用いた文章生成\n",
    "\n",
    "任意の言語モデルを用いて文章を生成する方法を見ていく。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答えは簡単。確率が高い単語の並びを選択するだけ。  \n",
    "モデルは語彙を持っており、その語彙から作れる全ての単語列に対して確率を割り当て、最も高い単語列を出力する。この単語列が、モデルが生成した文章となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際に文章を作ってみる。\n",
    "\n",
    "まずは言語モデルを作る。ここでは、いかなる単語列=文章に対してランダムな確率を出力するモデルを作る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文章を入力として、確率を出力する関数\n",
    "def langage_model(sentence):\n",
    "    prob = random.random() # 0 ~ 1 のランダムな値\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "できた。試しに文章を入れてみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7017995591740749"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"明日は晴れるといいな。\"\n",
    "prob = langage_model(sentence)\n",
    "prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確率が出てきた。これを使えば文章が生成できそうだ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では作っていこう、といきたいところだが、実は先程述べた生成手法には色々と問題がある。\n",
    "\n",
    "先程、モデルが持っている語彙から作れる全ての単語列に確率を割り当てると説明した。しかし、語彙の数が大きい場合、作ることのできる単語列は膨大な量になってしまう。\n",
    "\n",
    "そこで、**与えられた文脈**と持っている語彙から作れる単語列で考える。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例えば、モデルが以下の語彙を持っているとする。\n",
    "\n",
    "- 今日\n",
    "- 天気\n",
    "- おいしい\n",
    "- は\n",
    "- いい\n",
    "\n",
    "ここで、「今日 は いい」という単語列があったとする。このとき、この単語列と語彙から作れる文章を以下とする。\n",
    "\n",
    "- 今日 は いい 今日\n",
    "- 今日 は いい 天気\n",
    "- 今日 は いい おいしい\n",
    "- 今日 は いい は\n",
    "- 今日 は いい いい\n",
    "\n",
    "単語列の末尾に単語を1つ追加しただけだ。\n",
    "\n",
    "言語モデルは、これらに対して確率を割り当て、最も確率の高い単語列を出力する。そして、出力された単語列を再度モデルに与え、同様に単語列を生成する。これを繰り返すことで、文章を生成する。このような繰り返しの処理を**再帰的**な処理と呼ぶ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このような言語モデルの挙動は、与えられた文章から次の単語を予測しているように見える。言語モデルは「次の単語の予測」を繰り返すことで文章を生成する。モデルに与える文章は**文脈**と呼ぶ。\n",
    "\n",
    "もう少し厳密な解釈をすると、言語モデルは、与えられた文脈に続く単語の**確率分布**を予測するモデルとなる。その確率分布に従ってサンプリングを行うことで次の単語を出力し、それを繰り返すことで文章を生成する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では、この手法に基づいた言語モデルを作っていこう。\n",
    "\n",
    "与えられた文脈から次の単語の確率分布を予測し、それに基づいて次の単語をサンプリングするモデルを作る。確率分布はランダムとする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel:\n",
    "    def __init__(self, vocab: List[str]):\n",
    "        self.vocab = vocab # 語彙\n",
    "\n",
    "    def prob_predict(self, sentence): # 単語列=文章を入力として、確率を出力する\n",
    "        prob = random.random()\n",
    "        return prob\n",
    "\n",
    "    def sampling(self, dist): # 確率分布に従って単語をサンプリングする\n",
    "        word, = random.choices(self.vocab, weights=dist)\n",
    "        return word\n",
    "\n",
    "    def __call__(self, context):\n",
    "        # 各単語の確率を求める\n",
    "        probs = []\n",
    "        for word in self.vocab:\n",
    "            sentence = context + word # 文脈+単語で文章を生成\n",
    "            prob = self.prob_predict(sentence) # 文章を入力して確率を得る\n",
    "            probs.append(prob)\n",
    "\n",
    "        dist = [prob / sum(probs) for prob in probs] # 正規化\n",
    "        word = self.sampling(dist) # 単語をサンプリング\n",
    "        return word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "できた。\n",
    "\n",
    "適当に語彙と文脈を与えて次の単語を出力させてみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'は'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = [\"今日\", \"天気\", \"おいしい\", \"は\", \"いい\"] # 語彙\n",
    "model = LanguageModel(vocab) # 言語モデル\n",
    "\n",
    "context = \"今日はいい\" # 文脈\n",
    "word = model(context) # 次の単語をサンプリング\n",
    "word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この単語を文脈に追加して、再度次の単語を出力させる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今日はいいは\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'いい'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"今日はいい\" + word # 得られた単語を文脈に追加\n",
    "print(context)\n",
    "word = model(context) # 次の単語をサンプリング\n",
    "word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これを繰り返せば文章が出来そうだ。やってみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'はいい天気はは'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words = 5 # 生成する単語数\n",
    "sentence = \"\" # 最初の文脈\n",
    "\n",
    "for _ in range(n_words):\n",
    "    word = model(sentence) # 次の単語を予測\n",
    "    sentence += word # 文脈に単語を追加\n",
    "\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出来た。これが言語モデルによる文章生成である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は、いかなる単語列に対してランダムな確率を出力するモデルを作り、それを用いて文章を生成した。出力される確率はランダムなので、当然、めちゃくちゃな文章が生成される。\n",
    "\n",
    "ただ、もしモデルが、我々が自然だと感じる単語の並びに高い確率を割り当てられるようになった場合はどうだろう。我々にとって自然な文章が生成できるようになるのではないだろうか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次章以降では、人間が書いた大量の文章を用いて（学習させて）、モデルが自然な文章を生成できるようにする。自然な単語列に高い確率を割り当てられるようにする。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
