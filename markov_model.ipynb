{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# マルコフモデル\n",
    "\n",
    "*Markov Model*\n",
    "\n",
    "マルコフ過程に従う確率モデル。マルコフ連鎖とも。  \n",
    "マルコフ過程とは、ある状態から次の状態へ遷移する確率が、その状態のみに依存する確率過程のこと。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import random\n",
    "import markovify\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import MeCab"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 文章生成\n",
    "\n",
    "マルコフモデルを用いて文章を生成する。状態を単語とし、ある単語の次に続く単語の確率を予測する。\n",
    "\n",
    "学習データとして、いくつかの単語列（=文章）を用意する。学習データに出現する全ての単語を対象に、その次に続く単語とその確率を記録することで、マルコフモデルが完成する。確率は単語の出現頻度から定める。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例として以下の単語列を考えてみよう。\n",
    "\n",
    "- 今日 は いい 天気 です\n",
    "- 私 は 今日 カレー を 食べ ました\n",
    "- 私 は カレー が 好き です\n",
    "\n",
    "この3つの単語列を学習させてマルコフモデルを作成する。\n",
    "\n",
    "まず、1つ目に選ばれる可能性のある単語として「今日」と「私」がある。どちらが選ばれるかはランダムであるが、「今日」は1回、「私」は2回出現しているので、「今日」が選ばれる確率は1/3、「私」が選ばれる確率は2/3と定義する。  \n",
    "次に、この次に選ばれる可能性のある単語と確率を定義する。例えば、「今日」の次に来る可能性がある単語は「は」と「カレー」で、出現頻度は同じであるため確率は一様となる。また「私」の後は確定で「は」が来ることになる。  \n",
    "この流れで全ての単語について次に続く単語と確率を定義するとこうなる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'今日': {'は': 0.5, 'カレー': 0.5},\n",
       " 'は': {'いい': 0.3333333333333333,\n",
       "  '今日': 0.3333333333333333,\n",
       "  'カレー': 0.3333333333333333},\n",
       " 'いい': {'天気': 1.0},\n",
       " '天気': {'です': 1.0},\n",
       " '私': {'は': 1.0},\n",
       " 'カレー': {'を': 0.5, 'が': 0.5},\n",
       " 'を': {'食べ': 1.0},\n",
       " '食べ': {'ました': 1.0},\n",
       " 'が': {'好き': 1.0},\n",
       " '好き': {'です': 1.0}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    \"今日 は いい 天気 です\",\n",
    "    \"私 は 今日 カレー を 食べ ました\",\n",
    "    \"私 は カレー が 好き です\"\n",
    "]\n",
    "\n",
    "words = {}\n",
    "for sent in data:\n",
    "    sent = sent.split()\n",
    "    for w1, w2 in zip(sent[:-1], sent[1:]):\n",
    "        if w1 not in words:\n",
    "            words[w1] = {}\n",
    "        if w2 not in words[w1]:\n",
    "            words[w1][w2] = 0\n",
    "        words[w1][w2] += 1\n",
    "\n",
    "for w1 in words:\n",
    "    total = sum(words[w1].values())\n",
    "    for w2 in words[w1]:\n",
    "        words[w1][w2] /= total\n",
    "\n",
    "words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「今日」の次は「は」と「カレー」が$\\frac{1}{2}$ずつ、「は」の次は「いい」「今日」「カレー」が$\\frac{1}{3}$ずつという風に確率を定義することが出来た。\n",
    "\n",
    "では、この確率を用いて文章を生成してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今日 は 今日 は カレー が 好き です\n",
      "私 は カレー を 食べ ました\n",
      "私 は 今日 は 今日 カレー が 好き です\n",
      "今日 カレー を 食べ ました\n",
      "今日 カレー を 食べ ました\n",
      "私 は いい 天気 です\n",
      "私 は 今日 は 今日 カレー を 食べ ました\n",
      "私 は カレー が 好き です\n",
      "私 は 今日 は 今日 は カレー が 好き です\n",
      "私 は カレー を 食べ ました\n"
     ]
    }
   ],
   "source": [
    "def generate_sentence(words, start_words):\n",
    "    word, = random.choices(list(start_words), weights=start_words.values())\n",
    "    sentence = [word]\n",
    "    while word in words:\n",
    "        next_words = words[word]\n",
    "        word, = random.choices(list(next_words), weights=next_words.values())\n",
    "        sentence.append(word)\n",
    "    return ' '.join(sentence)\n",
    "\n",
    "for _ in range(10):\n",
    "    sentence = generate_sentence(words, {\"今日\": 1/3, \"私\": 2/3})\n",
    "    print(sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自然な文章もあれば、意味不明な文章もあるだろう。単語を予測する際に直前の単語のみを参照しているため、自然な文章を生成することは難しい。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### markovify\n",
    "\n",
    "マルコフモデルを用いて文章を生成するためのライブラリ。\n",
    "\n",
    "- [jsvine/markovify: A simple, extensible Markov chain generator.](https://github.com/jsvine/markovify)\n",
    "\n",
    "これを使うと簡単にマルコフモデルを用いた言語モデルを実装できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    \"今日 は いい 天気 です\",\n",
    "    \"私 は 今日 カレー を 食べ ました\",\n",
    "    \"私 は カレー が 好き です\"\n",
    "]\n",
    "model = markovify.Text(data, state_size=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで学習が完了した。文章を生成してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "私 は いい 天気 です\n",
      "今日 カレー が 好き です\n",
      "私 は カレー を 食べ ました\n",
      "私 は 今日 は いい 天気 です\n",
      "私 は 今日 カレー が 好き です\n",
      "今日 は カレー を 食べ ました\n",
      "今日 カレー が 好き です\n",
      "私 は いい 天気 です\n",
      "私 は いい 天気 です\n",
      "私 は 今日 カレー が 好き です\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    sentence = model.make_sentence()\n",
    "    print(sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 一般的なデータセットの活用\n",
    "\n",
    "ここまで、私が用意した3つの短文を学習データとして言語モデルを作成した。本節ではもう少し大きなデータセットを用いて言語モデルを作成する。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wiki40b\n",
    "\n",
    "Wikipediaの記事を集めたデータセット。  \n",
    "Tensorflow Datasetsに収録されているものを使用する。\n",
    "\n",
    "[wiki40b  |  TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/wiki40b?hl=en#wiki40bja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # tensorflowのログを非表示\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'): # 何故か勝手にGPUが使われるのでこちらからCPUを指定\n",
    "    ds = tfds.load('wiki40b/ja', split='test')\n",
    "ds = list(ds.as_numpy_iterator())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の様な辞書がまとまっている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': b'\\n_START_ARTICLE_\\n\\xe3\\x83\\x93\\xe3\\x83\\xbc\\xe3\\x83\\x88\\xe3\\x81\\x9f\\xe3\\x81\\x91\\xe3\\x81\\x97\\xe3\\x81\\xae\\xe6\\x95\\x99\\xe7\\xa7\\x91\\xe6\\x9b\\xb8\\xe3\\x81\\xab\\xe8\\xbc\\x89\\xe3\\x82\\x89\\xe3\\x81\\xaa\\xe3\\x81\\x84\\xe6\\x97\\xa5\\xe6\\x9c\\xac\\xe4\\xba\\xba\\xe3\\x81\\xae\\xe8\\xac\\x8e\\n_START_SECTION_\\n\\xe6\\xa6\\x82\\xe8\\xa6\\x81\\n_START_PARAGRAPH_\\n\\xe3\\x80\\x8c\\xe6\\x95\\x99\\xe7\\xa7\\x91\\xe6\\x9b\\xb8\\xe3\\x81\\xab\\xe3\\x81\\xaf\\xe6\\xb1\\xba\\xe3\\x81\\x97\\xe3\\x81\\xa6\\xe8\\xbc\\x89\\xe3\\x82\\x89\\xe3\\x81\\xaa\\xe3\\x81\\x84\\xe3\\x80\\x8d\\xe6\\x97\\xa5\\xe6\\x9c\\xac\\xe4\\xba\\xba\\xe3\\x81\\xae\\xe8\\xac\\x8e\\xe3\\x82\\x84\\xe3\\x81\\x97\\xe3\\x81\\x8d\\xe3\\x81\\x9f\\xe3\\x82\\x8a\\xe3\\x82\\x92\\xe5\\xa4\\x9a\\xe8\\xa7\\x92\\xe7\\x9a\\x84\\xe3\\x81\\xab\\xe6\\xa4\\x9c\\xe8\\xa8\\xbc\\xe3\\x81\\x97\\xe3\\x80\\x81\\xe6\\x97\\xa5\\xe6\\x9c\\xac\\xe4\\xba\\xba\\xe3\\x81\\xaeDNA\\xe3\\x82\\x92\\xe8\\xa7\\xa3\\xe6\\x98\\x8e\\xe3\\x81\\x99\\xe3\\x82\\x8b\\xe3\\x80\\x82_NEWLINE_\\xe6\\x96\\xb0\\xe6\\x98\\xa5\\xe7\\x95\\xaa\\xe7\\xb5\\x84\\xe3\\x81\\xa8\\xe3\\x81\\x97\\xe3\\x81\\xa6\\xe5\\xae\\x9a\\xe6\\x9c\\x9f\\xe7\\x9a\\x84\\xe3\\x81\\xab\\xe6\\x94\\xbe\\xe9\\x80\\x81\\xe3\\x81\\x95\\xe3\\x82\\x8c\\xe3\\x81\\xa6\\xe3\\x81\\x8a\\xe3\\x82\\x8a\\xe3\\x80\\x81\\xe5\\xb9\\xb4\\xe6\\x9c\\xab\\xe3\\x81\\xae\\xe5\\x8d\\x88\\xe5\\x89\\x8d\\xe4\\xb8\\xad\\xe3\\x81\\xab\\xe5\\x86\\x8d\\xe6\\x94\\xbe\\xe9\\x80\\x81\\xe3\\x81\\x95\\xe3\\x82\\x8c\\xe3\\x82\\x8b\\xe3\\x81\\xae\\xe3\\x81\\x8c\\xe6\\x81\\x92\\xe4\\xbe\\x8b\\xe3\\x81\\xa8\\xe3\\x81\\xaa\\xe3\\x81\\xa3\\xe3\\x81\\xa6\\xe3\\x81\\x84\\xe3\\x82\\x8b\\xe3\\x80\\x82',\n",
       " 'version_id': b'1848243370795951995',\n",
       " 'wikidata_id': b'Q11331136'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = ds[0]\n",
    "ex"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テキストの中身はこんな感じ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_START_ARTICLE_\n",
      "ビートたけしの教科書に載らない日本人の謎\n",
      "_START_SECTION_\n",
      "概要\n",
      "_START_PARAGRAPH_\n",
      "「教科書には決して載らない」日本人の謎やしきたりを多角的に検証し、日本人のDNAを解明する。_NEWLINE_新春番組として定期的に放送されており、年末の午前中に再放送されるのが恒例となっている。\n"
     ]
    }
   ],
   "source": [
    "print(ex['text'].decode())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "セクションごとにまとめる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of data: 89698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['「教科書には決して載らない」日本人の謎やしきたりを多角的に検証し、日本人のDNAを解明する。新春番組として定期的に放送されており、年末の午前中に再放送されるのが恒例となっている。',\n",
       " 'ライブドア社員であった初代代表取締役社長の山名真由によって企業内起業の形で創業。2005年に株式会社ライブドアから分割されて設立。かつてはライブドアホールディングス（現・LDH）の子会社であったが、ノンコア事業の整理にともない、株式会社ゲオ（現：株式会社ゲオホールディングス）に所有する全株式を譲渡し、同社の完全子会社となった。「ぽすれん」「ゲオ宅配レンタル」のオンラインDVD・CD・コミックレンタルサービス及び「GEO Online」と「ゲオアプリ」のアプリ・ウェブサイト運営の大きく分けて2事業を展開している。以前はDVD販売等のEコマースサービス「ぽすれんストア」、動画配信コンテンツ「ぽすれんBB」や電子書籍配信サービスの「GEO☆Books」事業も行っていた。オンラインDVDレンタル事業では会員数は10万人（2005年9月時点）。2006年5月よりCDレンタルを開始。同業他社には、カルチュア・コンビニエンス・クラブが運営する『TSUTAYA DISCAS』のほか、DMM.comが運営する『DMM.com オンラインDVDレンタル』がある。過去には「Yahoo!レンタルDVD」と「楽天レンタル」の運営を受託していた。',\n",
       " '2005年の一時期、東京のラジオ局、InterFMで、「堀江社長も使っているライブドアのぽすれん」というキャッチコピーでラジオCMを頻繁に行っていたことがあった。',\n",
       " '香川県内の農業協同組合の信用事業を統括する県域農協系金融機関であり、県内農業協同組合を会員とする。香川県は全県単一農協の香川県農業協同組合となったが、先に単一農協となった奈良県や沖縄県のケースと異なり、信連の統合は行われなかった。通称は「JA香川信連」または「JAバンク香川」。統一金融機関コードは3037。主に法人顧客を中心としており、個人取引は殆どない。県内の大型商業施設にある、他金融機関管理の共同ATMには香川信連の管轄のものがある。',\n",
       " '534年（永熙3年）、独孤信の子として生まれた。独孤信が父母妻子を捨てて長安に入ったため、独孤羅は東魏に取り残されて高氏の虜囚となった。独孤信が宇文護により処刑されると、ようやく釈放されて、中山に寓居した。北斉の独孤永業の一族として田宅を与えられた。北斉が滅亡し、楊堅が定州総管となると、楊堅の妻の独孤伽羅が兄の行方を捜索させて独孤羅を見つけ出し、初めて対面した。579年（大象元年）、功臣の子として楚安郡太守に任じられた。まもなく病のため辞職し、長安に帰った。580年（大象2年）、楊堅が北周の丞相となると、独孤羅は儀同大将軍の位を受け、楊堅の側近に仕えた。581年（開皇元年）、隋が建国されると、使持節・上開府・儀同大将軍の位を受けた。11月、右武衛将軍に転じた。582年（開皇2年）、父の趙国公の爵位を嗣いだ。592年（開皇12年）、大将軍・太子右衛率となった。593年（開皇13年）、涼州刺史に任じられた。597年（開皇17年）、涼州総管に任じられた。599年（開皇19年）2月6日、死去した。諡は徳といった。']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for sample in ds:\n",
    "    text = sample['text'].decode()\n",
    "    sections = text.split('_START_SECTION_')\n",
    "    for section in sections[1:]:\n",
    "        sentence = section.split('_START_PARAGRAPH_')[1]\n",
    "        sentence = sentence.replace('_NEWLINE_', '')\n",
    "        sentence = sentence.replace('\\n', '')\n",
    "        data.append(sentence)\n",
    "\n",
    "print('num of data:', len(data))\n",
    "data[:5] # examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分かち書き\n",
    "\n",
    "テキストを単語ごとに分割する。英語は元から単語ごとに分割されているが、日本語はそうではないので別途行う必要がある。  \n",
    "分かち書きには形態素解析器を使用する。色々な種類があるが、ここでは**MeCab**を使用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'私 は 猫 が 好き です 。 \\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = MeCab.Tagger('-Owakati') # 出力形式を分かち書きに指定\n",
    "result = tagger.parse('私は猫が好きです。')\n",
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これを使って、学習データの全てを単語ごとに分割する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['「 教科 書 に は 決して 載ら ない 」 日本 人 の 謎 や しきたり を 多角 的 に 検証 し 、 日本 人 の DNA を 解明 する 。 新春 番組 と し て 定期 的 に 放送 さ れ て おり 、 年末 の 午前 中 に 再 放送 さ れる の が 恒例 と なっ て いる 。',\n",
       " 'ライブ ドア 社員 で あっ た 初代 代表 取締 役 社長 の 山名 真由 に よっ て 企業 内 起業 の 形 で 創業 。 2005 年 に 株式 会社 ライブ ドア から 分割 さ れ て 設立 。 かつて は ライブ ドア ホールディングス （ 現 ・ LDH ） の 子 会社 で あっ た が 、 ノン コア 事業 の 整理 に ともない 、 株式 会社 ゲオ （ 現 ： 株式 会社 ゲオ ホールディングス ） に 所有 する 全 株式 を 譲渡 し 、 同社 の 完全 子 会社 と なっ た 。 「 ぽす れん 」 「 ゲオ 宅配 レンタル 」 の オン ライン DVD ・ CD ・ コミック レンタル サービス 及び 「 GEO Online 」 と 「 ゲオ アプリ 」 の アプリ ・ ウェブサイト 運営 の 大きく 分け て 2 事業 を 展開 し て いる 。 以前 は DVD 販売 等 の E コマース サービス 「 ぽす れん ストア 」 、 動画 配信 コンテンツ 「 ぽす れん BB 」 や 電子 書籍 配信 サービス の 「 GEO ☆ Books 」 事業 も 行っ て い た 。 オン ライン DVD レンタル 事業 で は 会員 数 は 10 万 人 （ 2005 年 9 月 時点 ） 。 2006 年 5 月 より CD レンタル を 開始 。 同業 他社 に は 、 カルチュア ・ コンビニエンス ・ クラブ が 運営 する 『 TSUTAYA DISCAS 』 の ほか 、 DMM . com が 運営 する 『 DMM . com オン ライン DVD レンタル 』 が ある 。 過去 に は 「 Yahoo ! レンタル DVD 」 と 「 楽天 レンタル 」 の 運営 を 受託 し て い た 。',\n",
       " '2005 年 の 一 時期 、 東京 の ラジオ 局 、 InterFM で 、 「 堀江 社長 も 使っ て いる ライブ ドア の ぽす れん 」 と いう キャッチ コピー で ラジオ CM を 頻繁 に 行っ て い た こと が あっ た 。',\n",
       " '香川 県 内 の 農業 協同 組合 の 信用 事業 を 統括 する 県域 農協 系 金融 機関 で あり 、 県内 農業 協同 組合 を 会員 と する 。 香川 県 は 全県 単一 農協 の 香川 県 農業 協同 組合 と なっ た が 、 先 に 単一 農協 と なっ た 奈良 県 や 沖縄 県 の ケース と 異なり 、 信連 の 統合 は 行わ れ なかっ た 。 通称 は 「 JA 香川 信連 」 また は 「 JA バンク 香川 」 。 統一 金融 機関 コード は 3037 。 主に 法人 顧客 を 中心 と し て おり 、 個人 取引 は 殆ど ない 。 県 内 の 大型 商業 施設 に ある 、 他 金融 機関 管理 の 共同 ATM に は 香川 信連 の 管轄 の もの が ある 。',\n",
       " '534 年 （ 永 熙 3 年 ） 、 独 孤 信 の 子 と し て 生まれ た 。 独 孤 信 が 父母 妻子 を 捨て て 長安 に 入っ た ため 、 独 孤 羅 は 東魏 に 取り残さ れ て 高 氏 の 虜囚 と なっ た 。 独 孤 信 が 宇文 護 に より 処刑 さ れる と 、 ようやく 釈放 さ れ て 、 中山 に 寓居 し た 。 北斉 の 独 孤 永業 の 一族 と し て 田宅 を 与え られ た 。 北斉 が 滅亡 し 、 楊堅 が 定 州 総管 と なる と 、 楊堅 の 妻 の 独 孤 伽羅 が 兄 の 行方 を 捜索 さ せ て 独 孤 羅 を 見つけ 出し 、 初めて 対面 し た 。 579 年 （ 大 象 元年 ） 、 功臣 の 子 と し て 楚 安 郡 太守 に 任じ られ た 。 ま も なく 病 の ため 辞職 し 、 長安 に 帰っ た 。 580 年 （ 大 象 2 年 ） 、 楊堅 が 北周 の 丞相 と なる と 、 独 孤 羅 は 儀同 大将軍 の 位 を 受け 、 楊堅 の 側近 に 仕え た 。 581 年 （ 開皇 元年 ） 、 隋 が 建国 さ れる と 、 使 持節 ・ 上 開府 ・ 儀同 大将軍 の 位 を 受け た 。 11 月 、 右 武衛 将軍 に 転じ た 。 582 年 （ 開皇 2 年 ） 、 父 の 趙 国公 の 爵位 を 嗣い だ 。 592 年 （ 開皇 12 年 ） 、 大将軍 ・ 太子 右 衛 率 と なっ た 。 593 年 （ 開皇 13 年 ） 、 涼州 刺史 に 任じ られ た 。 597 年 （ 開皇 17 年 ） 、 涼州 総管 に 任じ られ た 。 599 年 （ 開皇 19 年 ） 2 月 6 日 、 死去 し た 。 諡 は 徳 と いっ た 。']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_wakati = []\n",
    "for sentence in data:\n",
    "    data_wakati.append(tagger.parse(sentence).strip())\n",
    "\n",
    "data_wakati[:5] # examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習\n",
    "\n",
    "markovifyを使ってマルコフモデルを学習させ、文章を生成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = markovify.Text(data_wakati, state_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "太字は反応が当選。\n",
      "\n",
      "2014年5の進出によりセブンスポットをもたず、1991年頃に並行したようになるの目的とオスとなる直行列車は道のハノーヴァー・ウィック-Gijon-5月半ば、連邦官報を分断されたの4月25日、KUROBEアクアワールドは霞ケ浦海軍のクリーブランド・ミュージカルに並べられ、母親を設立されアラム・リーンまではされたの右側に換装された子ジカはスカチャンバレンティーノ・春日井市において次第に加入。2016–3日以降の未帆とサンケーブ型ベクトル、7月19,3日にあたる。QBといえば、マグロにしているが悪く、除草剤をとっている。\n",
      "\n",
      "神指町の地区や暴言は開催する。観察を用いることがゴムや日本の音楽家がシャープでも行われて生じるために、9打点、河瀬直美とした彗星の交配している。1980年労働でアルセーニエヴァ通りがとも最北端のコロムナ要塞の運行した時～ラワン間、北東北、これらの披露され、阿波公方足利義稙を投入に、カーゾン・1124年における生息地で、トップコンビであり、頭部にもてはやされた時には、世田谷区区間で熱心に創設されることが異民族の総合得点についていた。\n",
      "\n",
      "島式ホーム取締役社長、彼女が自分の基本に集住。確定して整備機構を始めの隠している。ミュージック・ロードレースを差し置いている。腹面がオーデル川以東の翌日にAAA級、IRASが、バルチースク空軍に砂糖の成人で、コースライセンスサーバシステムで出場は重要な対照的で1万下に所在不明な資産総額400がパンク・バスケス対空砲と題して追悼式蒸気蒸留法違反会員制と胞子を刺客を与えることがある。対する反省した。\n",
      "\n",
      "ヴァラは衆参両院で結婚したに郵便局を失われて、一定のバンド。6月には白ワインを息子、これにデヤン・文化が最も重い病気がちな特徴的に中国縦貫する。イギリスなどにNHK総合、下部組織に先んじてしまう。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    sentence = model.make_sentence().replace(' ', '')\n",
    "    print(sentence, end='\\n\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "語彙が増えたことで多様な文章が生成されるようになった。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
