{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# マルコフモデル\n",
    "\n",
    "まずはシンプルなモデルで言語モデルを学ぶ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Dict\n",
    "\n",
    "import markovify\n",
    "from datasets import load_dataset\n",
    "import MeCab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## マルコフモデル\n",
    "\n",
    "*Markov Model*\n",
    "\n",
    "マルコフ過程に従う確率モデル。マルコフ連鎖とも。マルコフ過程とは、ある状態から次の状態へ遷移する確率がその状態のみに依存する確率過程のこと。次の状態を予測する際に、過去の状態の情報を使わない。\n",
    "\n",
    "$$\n",
    "p(x_t | x_{t-1}, x_{t-2}, \\ldots, x_1) = p(x_t | x_{t-1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## マルコフモデルを用いた言語モデル\n",
    "\n",
    "マルコフモデルによる言語モデル（以後マルコフモデルと呼ぶ）では、状態を単語とし、ある単語の次に続く単語の確率を記述する。\n",
    "\n",
    "自然な文章を生成するためには、前章で作ったようなランダムな出力を行うモデルではなく、入力された文脈を考慮したモデルが必要となる。マルコフモデルはそのようなモデルの中で特に理解しやすいシンプルなモデルである。このモデルは、与えられた文脈の中の最後の単語のみに着目し、次の単語を予測する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "マルコフモデルでは、モデルが持っている全ての語彙に対して、その次に続く単語とその確率を記述する。\n",
    "\n",
    "例えば、モデルが以下の語彙を持っているとする。\n",
    "\n",
    "- 今日\n",
    "- カレー\n",
    "- 天気\n",
    "- おいしい\n",
    "- は\n",
    "- いい\n",
    "- 。\n",
    "\n",
    "これらに対して、次に続く単語とその確率を定める。適当に、主観で決めてみよう。\n",
    "\n",
    "単語 | 次に続く単語(確率)\n",
    "--- | ---\n",
    "今日 | は(1.0)\n",
    "カレー | は(1.0)\n",
    "天気 | は(0.5), 。(0.5)\n",
    "おいしい | 。(0.5), カレー(0.5)\n",
    "は | 今日(0.25), カレー(0.25), おいしい(0.25), いい(0.25)\n",
    "いい | 天気(0.5), 。(0.5)\n",
    "。 |\n",
    "\n",
    "句点は文の終わりを表すので、次に続く単語はないと考える。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "辞書として定義しておこう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    \"今日\": {\"は\": 1},\n",
    "    \"カレー\": {\"は\": 1},\n",
    "    \"天気\": {\"は\": 0.5, \"。\": 0.5},\n",
    "    \"おいしい\": {\"。\": 0.5, \"カレー\": 0.5},\n",
    "    \"は\": {\"今日\": 0.25, \"カレー\": 0.25, \"おいしい\": 0.25, \"いい\": 0.25},\n",
    "    \"いい\": {\"天気\": 0.5, \"。\": 0.5},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "マルコフモデルは、この確率に基づいて次の単語を予測する。それを繰り返して文章を生成する。\n",
    "\n",
    "モデルを作ってみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordProb = Dict[str, float]\n",
    "\n",
    "class MarkovModel:\n",
    "    def __init__(self, vocab: Dict[str, WordProb]):\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __call__(self, context):\n",
    "        last_word = context[-1]\n",
    "        words, dist = zip(*self.vocab[last_word].items())\n",
    "        word, = random.choices(words, weights=dist)\n",
    "        return word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "できた。これで文章を生成してみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(model: MarkovModel, start_word: str):\n",
    "    context = [start_word]\n",
    "    next_word = start_word\n",
    "    while next_word != \"。\":\n",
    "        next_word = model(context)\n",
    "        context.append(next_word)\n",
    "    return \" \".join(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初めの単語はこちらで指定する必要がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今日 は おいしい 。\n",
      "カレー は いい 天気 。\n"
     ]
    }
   ],
   "source": [
    "model = MarkovModel(vocab)\n",
    "print(generate_sentence(model, \"今日\"))\n",
    "print(generate_sentence(model, \"カレー\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文脈を考慮したモデルが作成できた。次に続く単語に対してまあまあ妥当な確率を手動で設定したので、少しは自然さが見られるはず。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## マルコフモデルの学習\n",
    "\n",
    "語彙と次の単語の確率をデータセットから自動で決定する。\n",
    "\n",
    "語彙に紐づいている次の単語の確率が、マルコフモデルの全てを表していると見られる。  \n",
    "前節ではこの確率を手動で定めたが、データを元に自動で設定する事を考える。\n",
    "\n",
    "このような、モデルの動きを決める値（マルコフモデルの場合は次に続く単語の確率）はパラメータと呼ぶ。そして、適切なパラメータをデータセットから自動で求める事を**機械学習**（や学習）と呼ぶ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ではやってみよう。\n",
    "\n",
    "データセットとして、いくつかの単語列を用意する。そして、データセットに出現する全ての単語を対象に、その次に続く単語とその確率を記録する。こうすることでマルコフモデルが完成する。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確率は単語の出現頻度から定める。例として以下の3つの単語列をデータセットとして考えてみよう。\n",
    "\n",
    "- 今日 は いい 天気 です 。\n",
    "- 今日 は カレー を 食べ ました 。\n",
    "- 私 は 今日 カレー を 食べ ました 。\n",
    "- 私 は カレー が 好き です 。\n",
    "\n",
    "このデータセットから、例えば、「今日」の次に来る可能性がある単語が「は」と「カレー」であると分かる。出現頻度を見ると、「は」が2回、「カレー」が1回出現しているため、「は」に2/3、「カレー」に1/3の確率を定義できる。このようにして、全ての単語について次に続く単語とその確率を定義する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際にやってみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    \"今日 は いい 天気 です 。\",\n",
    "    \"今日 は カレー を 食べ ました 。\",\n",
    "    \"私 は 今日 カレー を 食べ ました 。\",\n",
    "    \"私 は カレー が 好き です 。\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'今日': {'は': 0.6666666666666666, 'カレー': 0.3333333333333333},\n",
       " 'は': {'いい': 0.25, 'カレー': 0.5, '今日': 0.25},\n",
       " 'いい': {'天気': 1.0},\n",
       " '天気': {'です': 1.0},\n",
       " 'です': {'。': 1.0},\n",
       " 'カレー': {'を': 0.6666666666666666, 'が': 0.3333333333333333},\n",
       " 'を': {'食べ': 1.0},\n",
       " '食べ': {'ました': 1.0},\n",
       " 'ました': {'。': 1.0},\n",
       " '私': {'は': 1.0},\n",
       " 'が': {'好き': 1.0},\n",
       " '好き': {'です': 1.0}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {}\n",
    "for sent in data:\n",
    "    sent = sent.split()\n",
    "    for w1, w2 in zip(sent[:-1], sent[1:]):\n",
    "        if w1 not in vocab:\n",
    "            vocab[w1] = {}\n",
    "        if w2 not in vocab[w1]:\n",
    "            vocab[w1][w2] = 0\n",
    "        vocab[w1][w2] += 1\n",
    "\n",
    "for w1 in vocab:\n",
    "    total = sum(vocab[w1].values())\n",
    "    for w2 in vocab[w1]:\n",
    "        vocab[w1][w2] /= total\n",
    "\n",
    "vocab"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、マルコフモデルの学習が完了したことになる。このモデルでいくつか文章を生成してみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "私 は カレー が 好き です 。\n",
      "私 は 今日 は 今日 は いい 天気 です 。\n",
      "私 は いい 天気 です 。\n",
      "今日 カレー を 食べ ました 。\n",
      "今日 カレー を 食べ ました 。\n",
      "今日 は 今日 は 今日 カレー を 食べ ました 。\n",
      "私 は カレー を 食べ ました 。\n",
      "私 は カレー が 好き です 。\n",
      "私 は 今日 は いい 天気 です 。\n",
      "今日 は カレー を 食べ ました 。\n"
     ]
    }
   ],
   "source": [
    "model = MarkovModel(vocab)\n",
    "\n",
    "for _ in range(10):\n",
    "    start_word, = random.choices([\"今日\", \"私\"]) # 最初の単語はランダム\n",
    "    print(generate_sentence(model, start_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ランダムなモデルよりは自然な文章が生成されているのではないだろうか。\n",
    "\n",
    "これで、データセットからマルコフモデルを学習し、文章を生成することが出来た。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### markovify\n",
    "\n",
    "マルコフモデルを用いて文章を生成するためのライブラリ。\n",
    "\n",
    "- [jsvine/markovify: A simple, extensible Markov chain generator.](https://github.com/jsvine/markovify)\n",
    "\n",
    "これを使うと簡単にマルコフモデルを用いた言語モデルを実装できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['今日 は いい 天気 です 。',\n",
       " '今日 は カレー を 食べ ました 。',\n",
       " '私 は 今日 カレー を 食べ ました 。',\n",
       " '私 は カレー が 好き です 。']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data # 再掲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = markovify.Text(data, state_size=1) # 学習"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで学習が完了した。文章を生成してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今日 は 今日 は 今日 は いい 天気 です 。\n",
      "None\n",
      "None\n",
      "今日 は 今日 は 今日 は カレー を 食べ ました 。\n",
      "私 は 今日 は いい 天気 です 。\n",
      "今日 は 今日 カレー が 好き です 。\n",
      "今日 は 今日 カレー が 好き です 。\n",
      "私 は 今日 は いい 天気 です 。\n",
      "私 は 今日 は カレー が 好き です 。\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    sentence = model.make_sentence()\n",
    "    print(sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## より大きなデータセットの活用\n",
    "\n",
    "ここまで、私が用意した3つの短文をデータセットとして言語モデルを作成した。本節ではもう少し大きなデータセットを用いて言語モデルを作成する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "huggingfaceのdatasetsライブラリを使って、wikipediaの記事をデータセットとして取得する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'url', 'title', 'text'],\n",
       "        num_rows: 1389467\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki = load_dataset(\"wikimedia/wikipedia\", \"20231101.ja\", cache_dir=\"./data\")\n",
    "wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100万は多いので、適当に1000個の記事を取得する。あと記事全体も多いので、最初の1000文字だけを使う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "アンパサンド（&, ）は、並立助詞「…と…」を意味する記号である。ラテン語で「…と…」を表す接続詞 \"et\" の合字を起源とする。現代のフォントでも、Trebuchet MS など一部のフォントでは、\n",
      "言語（げんご）は、狭義には「声による記号の体系」をいう。広辞苑や大辞泉には次のように解説されている。人間が音声や文字を用いて思想・感情・意志等々を伝達するために用いる記号体系。およびそれを用いる\n",
      "日本語（にほんご、にっぽんご）は、日本国内や、かつての日本領だった国、そして国外移民や移住者を含む日本人同士の間で使用されている言語。日本は法令によって公用語を規定していないが、法令その他の公用文は全\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in range(100):\n",
    "    data.append(wiki[\"train\"][i][\"text\"][:1000])\n",
    "\n",
    "# Examples\n",
    "for i in range(3):\n",
    "    print(data[i][:100].replace(\"\\n\", \"\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### トークン化\n",
    "\n",
    "テキストをトークンごとに分割する。トークンとはモデルが扱う最小単位のことで、例えば単語が該当する。本節でも単語を最小単位=トークンとして、文章を単語列に変換する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "日本語の文章は単語間にスペースが入っていないので、こちらで分割する必要がある。ここには形態素解析器を使用する。これは自然言語処理で形態素解析（品詞の分析）に使用するツール。色々な種類があるが、ここでは[janome](https://mocobeta.github.io/janome/)を使用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from janome.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'私 は 猫 が 好き です 。'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "def tokenize(text):\n",
    "    return \" \".join(tokenizer.tokenize(text, wakati=True))\n",
    "\n",
    "tokenize(\"私は猫が好きです。\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これを使って、学習データの全てを単語ごとに分割する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "アンパサンド （&,   ） は 、 並立 助詞 「 … と … 」 を 意味 する 記号 で ある 。 ラテン語 で 「 … と … 」 を 表す 接続詞   \" et \"   の 合 字 を 起源\n",
      "言語 （ げん ご ） は 、 狭義 に は 「 声 による 記号 の 体系 」 を いう 。  広辞苑 や 大辞泉 に は 次 の よう に 解説 さ れ て いる 。  人間 が 音声 や \n",
      "日本語 （ に ほん ご 、 にっぽん ご ） は 、 日本 国内 や 、 かつて の 日本 領 だっ た 国 、 そして 国外 移民 や 移住 者 を 含む 日本人 同士 の 間 で 使用 さ れ \n"
     ]
    }
   ],
   "source": [
    "data_wakati = []\n",
    "for sentence in data:\n",
    "    data_wakati.append(tokenize(sentence))\n",
    "\n",
    "# Examples\n",
    "for i in range(3):\n",
    "    print(data_wakati[i][:100].replace(\"\\n\", \"\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実践\n",
    "\n",
    "markovifyを使ってマルコフモデルを学習させ、文章を生成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = markovify.NewlineText(data_wakati, state_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "メリーゴーランド、ラ・スペツィア＝リミニ線・システム\n",
      "古代エジプト。よってS→T/RPM形式\n",
      "もっとも古くから構成されたほか、他にはトランス\n",
      "政治関係に法的にリビア、絵画や背景にギリシア\n",
      "政治などである。また、他の宗教などが、チューリング認識可能性は西に据え付けても落選、昼間は多数の河川、\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    sentence = model.make_sentence(max_words=100).replace(\" \", \"\")\n",
    "    print(sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "語彙が増えたことで多様な文章が生成されるようになった。\n",
    "\n",
    "ただ、文脈の最後の単語しか考慮できないので、文章全体での自然さを作り出すことは難しい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## N階マルコフモデル\n",
    "\n",
    "直前のN単語を考慮するマルコフモデル。N=1の場合は通常のマルコフモデルとなる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習はこれまでと同様。N個の単語を1つの単位として次に続く単語の確率分布を求める。以下のデータセット:\n",
    "\n",
    "- 今日 は いい 天気 です 。\n",
    "- 今日 は カレー を 食べ ました 。\n",
    "- 私 は 今日 カレー を 食べ ました 。\n",
    "- 私 は カレー が 好き です 。\n",
    "\n",
    "から、N=2で確率分布を求めると:\n",
    "\n",
    "- 「今日 は」の次は「いい」が0.5、「カレー」が0.5\n",
    "- 「は いい」の次は「天気」が1\n",
    "- 「いい 天気」の次は「です」が1\n",
    "- ...\n",
    "\n",
    "て感じ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markovifyで実装してみる。`state_size`でNを指定する。N=2としてみよう（3以上だと上手く生成できなかった。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = markovify.NewlineText(data_wakati, state_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "音楽に関係する具体的ジェイオーク人物については、宇宙人、バビロニア人になった。\n",
      "初期ノード設定等に関しては当時の少女漫画の前衛的なピアノは88鍵を備え、音域が非常にシリアスなストーリーも盛り込まれている。特に、チューリング完全である。\n",
      "地球物理学の研究対象には含まれており、\n",
      "学術的な腱鞘炎などの影響を与えた。\n",
      "言語学のことをその存在様式を研究対象には顔を出さないので、言語に含まれる一方、その発明の産業上利用可能性、進歩性といった特許要件について特許庁による審査を経て10月号から10月号に永森裕二原作の『宗教生活の原初形態』や若い女性向けのゲームタイトル一覧\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    sentence = model.make_sentence(max_words=100)\n",
    "    if sentence:\n",
    "        sentence = sentence.replace(\" \", \"\")\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一応、ほんの少しは自然さが増したハズ。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
