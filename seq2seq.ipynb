{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq\n",
    "\n",
    "*Sequence to Sequence*.  \n",
    "*Encoder-Decoder Model*とも。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext import transforms\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchvision.transforms import Compose\n",
    "import MeCab\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "import random\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of data: 5304\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>japanese</th>\n",
       "      <th>english</th>\n",
       "      <th>chinese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#0001</td>\n",
       "      <td>Xではないかとつくづく疑問に思う</td>\n",
       "      <td>I often wonder if it might be X.</td>\n",
       "      <td>难道不会是X吗，我实在是感到怀疑。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#0002</td>\n",
       "      <td>Xがいいなといつも思います</td>\n",
       "      <td>I always think X would be nice.</td>\n",
       "      <td>我总觉得X不错。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#0003</td>\n",
       "      <td>それがあるようにいつも思います</td>\n",
       "      <td>It always seems like it is there.</td>\n",
       "      <td>我总觉得那好像是有的。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#0004</td>\n",
       "      <td>それが多すぎないかと正直思う</td>\n",
       "      <td>I honestly feel like there is too much.</td>\n",
       "      <td>老实说我觉得那太多了。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#0005</td>\n",
       "      <td>山田はみんなに好かれるタイプの人だと思う</td>\n",
       "      <td>I think that Yamada is the type everybody likes.</td>\n",
       "      <td>我想山田是受大家欢迎的那种人。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id              japanese   \n",
       "0  #0001      Xではないかとつくづく疑問に思う  \\\n",
       "1  #0002         Xがいいなといつも思います   \n",
       "2  #0003       それがあるようにいつも思います   \n",
       "3  #0004        それが多すぎないかと正直思う   \n",
       "4  #0005  山田はみんなに好かれるタイプの人だと思う   \n",
       "\n",
       "                                            english            chinese  \n",
       "0                  I often wonder if it might be X.  难道不会是X吗，我实在是感到怀疑。  \n",
       "1                   I always think X would be nice.           我总觉得X不错。  \n",
       "2                 It always seems like it is there.        我总觉得那好像是有的。  \n",
       "3           I honestly feel like there is too much.        老实说我觉得那太多了。  \n",
       "4  I think that Yamada is the type everybody likes.    我想山田是受大家欢迎的那种人。  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('data/JEC_basic_sentence_v1-3.xls', header=None)\n",
    "df.columns = ['id', 'japanese', 'english', 'chinese']\n",
    "print('num of data:', len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = MeCab.Tagger('-Owakati')\n",
    "def tokenize(data: List[str], l='en') -> List[List[str]]:\n",
    "    if l == 'ja':\n",
    "        return [tagger.parse(sentence).split() for sentence in data]\n",
    "    elif l == 'en':\n",
    "        return [sent.replace('.', ' .').lower().split() for sent in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ja = tokenize(df['japanese'], l='ja')\n",
    "text_en = tokenize(df['english'], l='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad, bos, eos, unk = '<pad>', '<bos>', '<eos>', '<unk>'\n",
    "specials = [pad, bos, eos, unk]\n",
    "vocab_ja = build_vocab_from_iterator(text_ja, specials=specials)\n",
    "vocab_en = build_vocab_from_iterator(text_en, specials=specials)\n",
    "\n",
    "def to_text(token_ids, l='en'):\n",
    "    vocab = eval(f'vocab_{l}')\n",
    "    tokens = []\n",
    "    for i in token_ids[1:]:\n",
    "        if i == vocab.get_stoi()[eos]:\n",
    "            break\n",
    "        tokens.append(vocab.get_itos()[i])\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_ja = Compose([\n",
    "    transforms.AddToken(bos, begin=True),\n",
    "    transforms.AddToken(eos, begin=False),\n",
    "    transforms.VocabTransform(vocab_ja),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_en = Compose([\n",
    "    transforms.AddToken(bos, begin=True),\n",
    "    transforms.AddToken(eos, begin=False),\n",
    "    transforms.VocabTransform(vocab_en),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "n_vocab_ja = len(vocab_ja)\n",
    "n_vocab_en = len(vocab_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_enc: torch.Size([32, 20])\n",
      "x_dec: torch.Size([32, 18])\n",
      "label: torch.Size([32, 18])\n"
     ]
    }
   ],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, in_text, out_text, in_transform, out_transform):\n",
    "        self.n_samples = len(in_text)\n",
    "        self.in_text = [in_transform(text) for text in in_text]\n",
    "        self.out_text = [out_transform(text) for text in out_text]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        in_text = self.in_text[index]\n",
    "        out_text = self.out_text[index]\n",
    "        return in_text, out_text[:-1], out_text[1:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "def to_padded_tensor(text_data: List[int], pad_value: int = 0) -> torch.Tensor:\n",
    "    data = pad_sequence(text_data, batch_first=True, padding_value=pad_value)\n",
    "    return data\n",
    "\n",
    "def collate_fn(batch):\n",
    "    enc_in_text, dec_in_text, dec_out_text = zip(*batch)\n",
    "    enc_in_text = to_padded_tensor(enc_in_text)\n",
    "    dec_in_text = to_padded_tensor(dec_in_text)\n",
    "    dec_out_text = to_padded_tensor(dec_out_text)\n",
    "    return enc_in_text, dec_in_text, dec_out_text\n",
    "\n",
    "dataset = TextDataset(text_ja, text_en, transform_ja, transform_en)\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "x_enc, x_dec, label = next(iter(dataloader))\n",
    "print('x_enc:', x_enc.shape)\n",
    "print('x_dec:', x_dec.shape)\n",
    "print('label:', label.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_id = vocab_ja.get_stoi()[eos]\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, n_vocab, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(\n",
    "            n_vocab,\n",
    "            embed_size,\n",
    "            padding_idx=vocab_ja.get_stoi()[pad]\n",
    "        )\n",
    "        self.rnn = nn.RNN(embed_size, hidden_size, batch_first=True)\n",
    "        # self.lstm = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        eos_positions = x == eos_id\n",
    "        x = self.embedding(x)\n",
    "        y, _ = self.rnn(x)\n",
    "        h = y[eos_positions] # (batch_size, hidden_size)\n",
    "        h = self.fc(h).unsqueeze(0) # (1, batch_size, hidden_size)\n",
    "        # _, h = self.lstm(x)\n",
    "        # h = self.fc(h[0][0])\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, n_vocab, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(n_vocab, embed_size)\n",
    "        self.rnn = nn.RNN(embed_size, hidden_size, batch_first=True)\n",
    "        # self.lstm = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, n_vocab)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        x = self.embedding(x)\n",
    "        y, h = self.rnn(x, h)\n",
    "        # y, h = self.lstm(x, h)\n",
    "        y = self.fc(y)\n",
    "        return y, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, n_in_vocab, n_out_vocab, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(n_in_vocab, embed_size, hidden_size)\n",
    "        self.decoder = Decoder(n_out_vocab, embed_size, hidden_size)\n",
    "\n",
    "    def forward(self, x_enc, x_dec):\n",
    "        h = self.encoder(x_enc)\n",
    "        y, _ = self.decoder(x_dec, h)\n",
    "        # h0 = h.unsqueeze(0)\n",
    "        # c0 = torch.zeros_like(h0)\n",
    "        # y, _ = self.decoder(x_dec, (h0, c0))\n",
    "        return y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=vocab_en[pad])\n",
    "def train(model, optimizer, n_epochs):\n",
    "    eval_tokens = []\n",
    "    model.train()\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        epoch_loss = 0\n",
    "        for x_enc, x_dec, label in tqdm(dataloader, desc=f'{epoch}/{n_epochs}', disable=True):\n",
    "            optimizer.zero_grad()\n",
    "            x_enc = x_enc.to(device)\n",
    "            x_dec = x_dec.to(device)\n",
    "            label = label.to(device)\n",
    "            y_pred = model(x_enc, x_dec)\n",
    "            loss = criterion(y_pred.reshape(-1, y_pred.shape[-1]), label.ravel())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        eval_tokens.append((y_pred, label))\n",
    "        print(f'{epoch}/{n_epochs} loss: {epoch_loss/len(dataloader)}', flush=True)\n",
    "    return eval_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(len(vocab_ja), len(vocab_en), 1024, 1024).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eval_tokensについては後程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/60 loss: 5.835270801222468\n",
      "2/60 loss: 4.892273575426584\n",
      "3/60 loss: 4.576794963285147\n",
      "4/60 loss: 4.324355901005757\n",
      "5/60 loss: 4.098599929407419\n",
      "6/60 loss: 3.891183881874544\n",
      "7/60 loss: 3.69426362773022\n",
      "8/60 loss: 3.5012600637343994\n",
      "9/60 loss: 3.3184977022998305\n",
      "10/60 loss: 3.140416044786752\n",
      "11/60 loss: 2.9700641531542122\n",
      "12/60 loss: 2.799751356423619\n",
      "13/60 loss: 2.6396425689559386\n",
      "14/60 loss: 2.4855928866260024\n",
      "15/60 loss: 2.338073099952146\n",
      "16/60 loss: 2.1948005643235633\n",
      "17/60 loss: 2.065133432307875\n",
      "18/60 loss: 1.9391252556479122\n",
      "19/60 loss: 1.8168115723563965\n",
      "20/60 loss: 1.700798583317952\n",
      "21/60 loss: 1.5883989190480796\n",
      "22/60 loss: 1.4854144647897007\n",
      "23/60 loss: 1.385881856263402\n",
      "24/60 loss: 1.2935746671205544\n",
      "25/60 loss: 1.2044040517634655\n",
      "26/60 loss: 1.1196834628122398\n",
      "27/60 loss: 1.0408244897802192\n",
      "28/60 loss: 0.9677115822412882\n",
      "29/60 loss: 0.8982452667621245\n",
      "30/60 loss: 0.8315635398927942\n",
      "31/60 loss: 0.7655266817793789\n",
      "32/60 loss: 0.7054116743874838\n",
      "33/60 loss: 0.6493757654385395\n",
      "34/60 loss: 0.5981201554637358\n",
      "35/60 loss: 0.5481854826211929\n",
      "36/60 loss: 0.5018254500555704\n",
      "37/60 loss: 0.4577679768743285\n",
      "38/60 loss: 0.4183667022061635\n",
      "39/60 loss: 0.3830072973147932\n",
      "40/60 loss: 0.35355894985687303\n",
      "41/60 loss: 0.31791931983218136\n",
      "42/60 loss: 0.2867471889918109\n",
      "43/60 loss: 0.26026108860969543\n",
      "44/60 loss: 0.23450604503054218\n",
      "45/60 loss: 0.21072217579706606\n",
      "46/60 loss: 0.19073467970971603\n",
      "47/60 loss: 0.1727260563028864\n",
      "48/60 loss: 0.15713674498789282\n",
      "49/60 loss: 0.14171117741659464\n",
      "50/60 loss: 0.1274049607027008\n",
      "51/60 loss: 0.11432978739760008\n",
      "52/60 loss: 0.10606381934450333\n",
      "53/60 loss: 0.097623224897557\n",
      "54/60 loss: 0.08959485877709217\n",
      "55/60 loss: 0.09275179235152452\n",
      "56/60 loss: 0.08901712486901915\n",
      "57/60 loss: 0.07866372266806752\n",
      "58/60 loss: 0.06009746881493603\n",
      "59/60 loss: 0.048562009201710485\n",
      "60/60 loss: 0.040505780221288465\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 60\n",
    "eval_tokens = train(model, optimizer, n_epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 翻訳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def translate(model, text, max_len=100):\n",
    "    model.eval()\n",
    "    tokens = tokenize([text], 'ja')[0]\n",
    "    tokens = transform_ja(tokens).unsqueeze(0).to(device)\n",
    "    h = model.encoder(tokens)\n",
    "    # h0 = h.unsqueeze(0)\n",
    "    # c0 = torch.zeros_like(h0)\n",
    "    # h = (h0, c0)\n",
    "    next_token = vocab_en[bos]\n",
    "\n",
    "    tokens = []\n",
    "    for _ in range(max_len):\n",
    "        next_token = torch.tensor(next_token).reshape(1, 1).to(device)\n",
    "        y, h = model.decoder(next_token, h)\n",
    "        y = F.softmax(y.ravel(), dim=0)\n",
    "        # next_token = random.choices(range(len(y)), weights=y)[0] # 確率的な出力\n",
    "        next_token = y.argmax().item() # 決定的な出力\n",
    "        if next_token == vocab_en[eos]:\n",
    "            break\n",
    "        tokens.append(next_token)\n",
    "    return ' '.join([vocab_en.get_itos()[t] for t in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i often wonder if it might be x .'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(model, 'Xではないかとつくづく疑問に思う')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i think that yamada is the type everybody likes .'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(model, '山田はみんなに好かれるタイプの人だと思う')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
