{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq\n",
    "\n",
    "*Sequence to Sequence*.  \n",
    "*Encoder-Decoder Model*とも。\n",
    "\n",
    "2つのモデルを用いて、入力されたシーケンスに基づいた別のシーケンスを出力するモデル。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これまで、RNN（やLSTM）を用いて、入力した単語列に続く単語を予測するモデルを作成し、単語の予測を繰り返すことで文章を生成した。\n",
    "\n",
    "RNNは時系列の情報を保持するために隠れ状態$h_t$を用いる。隠れ状態の初期値$h_0$は0ベクトルとしているが、ここで、何らかの入力データから生成したベクトルを$h_0$として用いることを考える。このとき、上手く学習させれば、その入力に基づいた文章を生成できるのではないか。\n",
    "\n",
    "例えば、入力を画像をとし、CNNを用いて抽出した特徴量を$h_0$として用いるようにすれば、入力画像に基づいた文章が生成できる。画像のキャプション生成などに応用できそう。隠れ状態を通じてRNNからCNNまで逆伝播が繋がるので、画像と文章のペアさえ用意すれば学習できそう。というかできる[1]。\n",
    "\n",
    "[1] [Show and Tell: A Neural Image Caption Generator](https://arxiv.org/abs/1411.4555)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では、入力に文章を用いることはできないだろうか。RNNに文章を入力し、最後に出力された隠れ状態を文章ベクトルとする。これを別のRNNへの入力$h_0$とすれば、入力文に基づいた文章生成が可能になる。\n",
    "\n",
    "この発想は翻訳タスクに大きく役立つ。入力と出力に同じ意味を持った異なる言語の文章を設定すれば、入力文と同じ意味を持った文章生成が可能になる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本章ではこの翻訳モデルを作成する。入力に日本語文、出力に入力と同じ意味を持つ英語文を設定し、日本語→英語の翻訳を行うモデルを作成する。こういった、シーケンスをシーケンスに変換するモデルを *Seq2Seq (Sequence to Sequence)* と呼ぶ。\n",
    "\n",
    "Seq2Seqは以下の二つのRNNから構成される。\n",
    "\n",
    "- ***Encoder*** : 文章ベクトルを生成するRNN\n",
    "- ***Decoder*** : 文章ベクトルを受け取って出力文を生成するRNN\n",
    "\n",
    "このことから***Encoder-Decoderモデル***とも呼ばれる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "import math\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import sentencepiece as spm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from dlprog import train_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prog = train_progress(\n",
    "    width=20,\n",
    "    with_test=True,\n",
    "    label=\"ppl train\",\n",
    "    round=2,\n",
    "    agg_fn=lambda s, w: math.exp(s / w)\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 対訳コーパス\n",
    "\n",
    "翻訳モデルを作るには、同じ意味を持つ文章が複数の言語でまとまっているデータが必要。このようなデータは対訳コーパスと呼んだりする。\n",
    "\n",
    "本章では以下のデータセットから日本語と英語の対訳コーパスを使用する。\n",
    "\n",
    "- [iwslt2017  |  TensorFlow Datasets](https://www.tensorflow.org/datasets/community_catalog/huggingface/iwslt2017?hl=ja#iwslt2017-en-ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tfds.load(\n",
    "    \"huggingface:iwslt2017/iwslt2017-en-ja\",\n",
    "    data_dir=\"data\",\n",
    "    split=\"train\"\n",
    ")\n",
    "ds = list(ds.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of data: 223108 \n",
      "\n",
      "腐敗が 病的に民主主義を 破壊してしまうということです つまり どのようなシステムであっても その構成員がごく少数の 構成員によって選ばれる場合には その構成員がごく少数の 構成員によって選ばれる場合には それは ごく少数の構成員が ごくごく少数の構成員が 改革を阻止できることを意味します\n",
      "It's a pathological, democracy-destroying corruption, because in any system where the members are dependent upon the tiniest fraction of us for their election, that means the tiniest number of us, the tiniest, tiniest number of us, can block reform.\n",
      "\n",
      "これは大変なことです\n",
      "This is a big deal.\n",
      "\n",
      "疑問というのは 西洋社会におけるすべての議論は 課税レベルに関することです\n",
      "We ask the question -- the whole debate in the Western world is about the level of taxation.\n",
      "\n",
      "つまり大きな意味では 技術というのは何も こんな機器だけをさすのではないのです 習慣、テクニック、心理的手法 なども含めて 技術と呼べるのです\n",
      "So in a broad sense, we don't need to think about technology as only little gadgets, like these things here, but even institutions and techniques, psychological methods and so forth.\n",
      "\n",
      "ひも理論が難しいなんて人もいますが 楽なもんです\n",
      "And some people think that string theory is tough.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_ja = []\n",
    "data_en = []\n",
    "for sample in ds:\n",
    "    ja = sample[\"translation\"][\"ja\"].decode()\n",
    "    en = sample[\"translation\"][\"en\"].decode()\n",
    "    data_ja.append(ja)\n",
    "    data_en.append(en)\n",
    "\n",
    "print(\"num of data:\", len(data_ja), \"\\n\")\n",
    "for _ in range(5):\n",
    "    i = random.randint(0, len(data_ja))\n",
    "    print(data_ja[i])\n",
    "    print(data_en[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "書き出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile_ja = \"data/iwslt2017_ja.txt\"\n",
    "with open(textfile_ja, \"w\") as f:\n",
    "    f.write(\"\\n\".join(data_ja))\n",
    "\n",
    "textfile_en = \"data/iwslt2017_en.txt\"\n",
    "with open(textfile_en, \"w\") as f:\n",
    "    f.write(\"\\n\".join(data_en))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile_ja = f\"data/iwslt2017_ja.txt\"\n",
    "textfile_en = f\"data/iwslt2017_en.txt\"\n",
    "\n",
    "with open(textfile_ja) as f:\n",
    "    data_ja = f.read().splitlines()\n",
    "with open(textfile_en) as f:\n",
    "    data_en = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "日本語、英語別々にトークナイザを作成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_prefix_ja = f\"models/tokenizer_iwslt2017_ja\"\n",
    "tokenizer_prefix_en = f\"models/tokenizer_iwslt2017_en\"\n",
    "pad_id = 3\n",
    "vocab_size = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.SentencePieceTrainer.Train(\n",
    "    input=textfile_ja,\n",
    "    model_prefix=tokenizer_prefix_ja,\n",
    "    vocab_size=vocab_size,\n",
    "    pad_id=pad_id\n",
    ")\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    input=textfile_en,\n",
    "    model_prefix=tokenizer_prefix_en,\n",
    "    vocab_size=vocab_size,\n",
    "    pad_id=pad_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of vocabrary (ja): 8000\n",
      "num of vocabrary (en): 8000\n"
     ]
    }
   ],
   "source": [
    "sp_ja = spm.SentencePieceProcessor(f\"{tokenizer_prefix_ja}.model\")\n",
    "sp_en = spm.SentencePieceProcessor(f\"{tokenizer_prefix_en}.model\")\n",
    "\n",
    "unk_id = sp_ja.unk_id()\n",
    "bos_id = sp_ja.bos_id()\n",
    "eos_id = sp_ja.eos_id()\n",
    "pad_id = sp_ja.pad_id()\n",
    "\n",
    "n_vocab_ja = len(sp_ja)\n",
    "n_vocab_en = len(sp_en)\n",
    "print(\"num of vocabrary (ja):\", n_vocab_ja)\n",
    "print(\"num of vocabrary (en):\", n_vocab_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "トークン化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ids_ja = sp_ja.encode(data_ja)\n",
    "data_ids_en = sp_en.encode(data_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOS, EOSの追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ids_ja, ids_en in zip(data_ids_ja, data_ids_en):\n",
    "    ids_en.insert(0, bos_id)\n",
    "    ids_ja.append(eos_id)\n",
    "    ids_en.append(eos_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習データの作成\n",
    "\n",
    "入力文と正解のペアを作成する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoderへの入力（入力文）とDecoderの出力（正解）のペアを作成する。また、Decoderへの入力を考える必要がある。今回は教師強制を採用し、出力文の頭に\\<BOS>を付与したものをDecoderへの入力とする。\n",
    "\n",
    "例）\n",
    "Encoderへの入力（入力文） | Decoderへの入力 | Decoderの出力（出力文）\n",
    "--- | --- | ---\n",
    "夏 休み が 終わり ました 。 \\<EOS> | \\<BOS> Summer vacation is over . | Summer vacation is over . \\<EOS>\n",
    "ツイッター は 亡くなり ました 。 \\<EOS> | \\<BOS> Twitter is dead . | Twitter is dead . \\<EOS>\n",
    "今日 から X で 暮らし ましょう 。 \\<EOS> | \\<BOS> Let 's live in X from today . | Let 's live in X from today . \\<EOS>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataLoader`の作成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train data: 178487\n",
      "num of test data: 44621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 53]), torch.Size([32, 85]), torch.Size([32, 85]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data_ids_ja, data_ids_en):\n",
    "        self.data_ja = [torch.tensor(ids) for ids in data_ids_ja]\n",
    "        self.data_en = [torch.tensor(ids) for ids in data_ids_en]\n",
    "        self.n_data = len(self.data_ja)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ja = self.data_ja[idx]\n",
    "        en = self.data_en[idx]\n",
    "        x_enc = ja # Encoderへの入力\n",
    "        x_dec = en[:-1] # Decoderへの入力\n",
    "        y_dec = en[1:] # Decoderの出力\n",
    "        return x_enc, x_dec, y_dec\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_data\n",
    "\n",
    "def collate_fn(batch): # padding\n",
    "    x_enc, x_dec, y_dec= zip(*batch)\n",
    "    x_enc = pad_sequence(x_enc, batch_first=True, padding_value=pad_id)\n",
    "    x_dec = pad_sequence(x_dec, batch_first=True, padding_value=pad_id)\n",
    "    y_dec = pad_sequence(y_dec, batch_first=True, padding_value=pad_id)\n",
    "    return x_enc, x_dec, y_dec\n",
    "\n",
    "dataset = TextDataset(data_ids_ja, data_ids_en)\n",
    "train_dataset, test_dataset = random_split(dataset, [0.8, 0.2])\n",
    "print(\"num of train data:\", len(train_dataset))\n",
    "print(\"num of test data:\", len(test_dataset))\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    drop_last=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# example\n",
    "x_enc, x_dec, y_dec = next(iter(train_loader))\n",
    "x_enc.shape, x_dec.shape, y_dec.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Seq2Seqを用いた翻訳モデル\n",
    "\n",
    "Encoder、Decoderを作成し、Seq2Seqモデルを作成する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "\n",
    "入力文を入れて隠れ状態を出力するだけのRNN。LSTMと線形層で作る。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、何を隠れ状態とするかを考える。Decoderに渡したい隠れ状態として満たしてほしい条件は以下である。\n",
    "\n",
    "- （padを除いた）全ての入力を参照して出力されている\n",
    "- 固定長\n",
    "\n",
    "これらを全て満たしていれば何でもよい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "よくあるのは最後の隠れ状態。これが一番シンプルで実装も簡単。\n",
    "\n",
    "ただこれだと学習時にpadトークンが隠れ状態に関与してしまう。多くの場合、推論時にpadトークンは存在しないため、学習時もpadトークンを考慮しない出力をさせた方が良さそう。また、padの数が多くなるにつれて隠れ状態がある一定の値に収束してしまう（経験談）。RNNに同じトークンを何度も入力することで隠れ状態が収束してしまうみたい。そうなってしまうと、入力文に依る隠れ状態の違いが少なくなり、入力文を考慮した出力が行えない。\n",
    "\n",
    "ではどうするかというと、「padを除いた最後の隠れ状態」とする。eosトークンが入力された時点の隠れ状態とも言える。これで上記の問題を解決できる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "他にもいくつかの案が考えられる。例えば、「padを除いた全ての隠れ状態の平均」とか。これも条件を満たす。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、RNNを双方向にするという手法もある。Encoderは入力文の特徴を抽出できれば良いので、文の初めから順に処理しなければならない訳ではない。例えば逆から処理してもよい。\n",
    "\n",
    "双方向RNNでは、順方向と逆方向の双方向で演算を行い、各時刻で二つの隠れ状態を出力する。両端の時刻の隠れ状態を取得することで二種類の隠れ状態が得られ、それらを足すないしは結合することで最終的な一つの隠れ状態が得られる。\n",
    "\n",
    "双方向RNNは`torch.nn.RNN`の引数`bidirectional=True`で実装できる。ただ、各隠れ状態の出力がpadトークンを除いて行われて欲しいという望みがあり、それを実現するための実装が難しそうなので、今回は不採用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結局どうしようかという感じだが、無難に「padを除いた最後の隠れ状態」を採用する。Encoderを以下のように実装する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_vocab,\n",
    "        embed_size,\n",
    "        hidden_size,\n",
    "        dropout=0.2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(n_vocab, embed_size)\n",
    "        self.lstm1 = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc_skip = nn.Linear(embed_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len)\n",
    "        \"\"\"\n",
    "        eos_pos = x == eos_id\n",
    "            # eosに対応する位置のみがTrueとなったTensor: (batch_size, seq_len)\n",
    "        x = self.embedding(x) # (batch_size, seq_len, embed_size)\n",
    "        skip = self.fc_skip(x)\n",
    "        hs1, _ = self.lstm1(x) # (batch_size, seq_len, hidden_size)\n",
    "        hs1 = hs1 + skip\n",
    "        hs1 = self.dropout(hs1)\n",
    "        hs2, _ = self.lstm2(hs1)\n",
    "        hs2 = self.dropout(hs2)\n",
    "        h1 = hs1[eos_pos] # (batch_size, hidden_size)\n",
    "        h2 = hs2[eos_pos] # (batch_size, hidden_size)\n",
    "        return h1, h2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "\n",
    "Encoderから出力された隠れ状態を受け取り、出力文を生成するRNN。Encoder同様、LSTMと線形層で作る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_vocab,\n",
    "        embed_size,\n",
    "        hidden_size,\n",
    "        dropout=0.2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(n_vocab, embed_size)\n",
    "        self.lstm1 = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, n_vocab)\n",
    "        self.fc_skip = nn.Linear(embed_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, hc):\n",
    "        hc1, hc2 = hc\n",
    "        x = self.embedding(x) # (batch_size, seq_len, embed_size)\n",
    "        skip = self.fc_skip(x) # (batch_size, seq_len, hidden_size)\n",
    "        hs, hc1 = self.lstm1(x, hc1) # (batch_size, seq_len, hidden_size)\n",
    "        hs = hs + skip\n",
    "        hs = self.dropout(hs)\n",
    "        hs, hc2 = self.lstm2(hs, hc2)\n",
    "        y = self.fc(hs) # (batch_size, seq_len, n_vocab)\n",
    "        return y, (hc1, hc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq\n",
    "\n",
    "EncoderとDecoderを合わせて、入力から出力までの一連の処理を行うモデルを作る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x_enc, x_dec):\n",
    "        h = self.encoder(x_enc)\n",
    "        hc = self.get_hc(h)\n",
    "        y, _ = self.decoder(x_dec, hc)\n",
    "        return y\n",
    "\n",
    "    def get_hc(self, h):\n",
    "        h1, h2 = h\n",
    "        h1 = h1.unsqueeze(0)\n",
    "        h2 = h2.unsqueeze(0)\n",
    "        c1 = torch.zeros_like(h1)\n",
    "        c2 = torch.zeros_like(h2)\n",
    "        hc = ((h1, c1), (h2, c2))\n",
    "        return hc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of parameters: 21,488,960\n"
     ]
    }
   ],
   "source": [
    "hidden_size, embed_size = 512, 512\n",
    "encoder = Encoder(n_vocab_ja, embed_size, hidden_size)\n",
    "decoder = Decoder(n_vocab_en, embed_size, hidden_size)\n",
    "model = Seq2Seq(encoder, decoder).to(device)\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"num of parameters: {n_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 実践"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = nn.CrossEntropyLoss(ignore_index=pad_id)\n",
    "def loss_fn(y, t):\n",
    "    loss = cross_entropy(y.reshape(-1, n_vocab_ja), t.ravel())\n",
    "    return loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_model(model):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for x_enc, x_dec, y_dec in test_loader:\n",
    "        x_enc = x_enc.to(device)\n",
    "        x_dec = x_dec.to(device)\n",
    "        y_dec = y_dec.to(device)\n",
    "\n",
    "        y = model(x_enc, x_dec)\n",
    "        loss = loss_fn(y, y_dec)\n",
    "        losses.append(loss.item())\n",
    "    loss = sum(losses) / len(losses)\n",
    "    ppl = math.exp(loss)\n",
    "    return ppl\n",
    "\n",
    "def train(model, optimizer, n_epochs, prog_unit=1):\n",
    "    prog.start(n_iter=len(train_loader), n_epochs=n_epochs, unit=prog_unit)\n",
    "    for _ in range(n_epochs):\n",
    "        model.train()\n",
    "        for x_enc, x_dec, y_dec in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            x_enc = x_enc.to(device)\n",
    "            x_dec = x_dec.to(device)\n",
    "            y_dec = y_dec.to(device)\n",
    "\n",
    "            y = model(x_enc, x_dec)\n",
    "            loss = loss_fn(y, y_dec)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            prog.update(loss.item())\n",
    "\n",
    "        if prog.now_epoch % prog_unit == 0:\n",
    "            test_ppl = eval_model(model)\n",
    "            prog.memo(f\"test: {test_ppl:.2f}\", no_step=True)\n",
    "        prog.memo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/20: #################### 100% [00:03:32.11] ppl train: 156.44, test: 104.08 \n",
      " 2/20: #################### 100% [00:03:24.90] ppl train: 90.18, test: 80.36  \n",
      " 3/20: #################### 100% [00:03:26.84] ppl train: 72.60, test: 68.94 \n",
      " 4/20: #################### 100% [00:03:27.91] ppl train: 62.57, test: 61.82 \n",
      " 5/20: #################### 100% [00:03:30.71] ppl train: 55.74, test: 57.06 \n",
      " 6/20: #################### 100% [00:03:33.10] ppl train: 50.54, test: 53.48 \n",
      " 7/20: #################### 100% [00:03:32.68] ppl train: 46.43, test: 50.73 \n",
      " 8/20: #################### 100% [00:03:30.39] ppl train: 43.05, test: 48.79 \n",
      " 9/20: #################### 100% [00:03:29.70] ppl train: 40.25, test: 47.13 \n",
      "10/20: #################### 100% [00:03:31.25] ppl train: 37.86, test: 45.95 \n",
      "11/20: #################### 100% [00:03:30.12] ppl train: 35.75, test: 44.94 \n",
      "12/20: #################### 100% [00:03:30.12] ppl train: 33.92, test: 44.23 \n",
      "13/20: #################### 100% [00:03:28.33] ppl train: 32.29, test: 43.86 \n",
      "14/20: #################### 100% [00:03:28.65] ppl train: 30.84, test: 43.25 \n",
      "15/20: #################### 100% [00:03:28.04] ppl train: 29.51, test: 43.03 \n",
      "16/20: #################### 100% [00:03:28.25] ppl train: 28.30, test: 42.67 \n",
      "17/20: #################### 100% [00:03:28.10] ppl train: 27.20, test: 42.73 \n",
      "18/20: #################### 100% [00:03:28.88] ppl train: 26.20, test: 42.57 \n",
      "19/20: #################### 100% [00:03:28.58] ppl train: 25.27, test: 42.48 \n",
      "20/20: #################### 100% [00:03:29.37] ppl train: 24.42, test: 42.75 \n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, n_epochs=20, prog_unit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"models/lm_seq2seq.pth\"\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 翻訳\n",
    "\n",
    "作成したモデルに日本語文を入力し、英語に翻訳して出力する。決定的な出力にする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_sampling(y, decisive=True):\n",
    "    y = y.squeeze(0, 1)\n",
    "    if decisive:\n",
    "        token = y.argmax().item()\n",
    "    else:\n",
    "        y[unk_id] = -torch.inf\n",
    "        probs = F.softmax(y, dim=-1)\n",
    "        token, = random.choices(range(n_vocab_en), weights=probs)\n",
    "    return token\n",
    "\n",
    "\n",
    "bos_id = sp_en.bos_id()\n",
    "eos_id = sp_en.eos_id()\n",
    "@torch.no_grad()\n",
    "def translate(\n",
    "    model: nn.Module,\n",
    "    in_text: str, # 入力文（日本語）\n",
    "    max_len: int = 100, # 出力のトークン数の上限\n",
    "    decisive: bool = True, # サンプリングを決定的にするか\n",
    ") -> str:\n",
    "    model.eval()\n",
    "    in_ids = sp_ja.encode(in_text)\n",
    "    in_ids = torch.tensor(in_ids + [eos_id], device=device).unsqueeze(0)\n",
    "\n",
    "    h_enc = model.encoder(in_ids)\n",
    "    hc = model.get_hc(h_enc)\n",
    "    next_token = bos_id\n",
    "\n",
    "    token_ids = []\n",
    "    while len(token_ids) <= max_len and next_token != eos_id:\n",
    "        x = torch.tensor([next_token], device=device).reshape(1, 1)\n",
    "        y, hc = model.decoder(x, hc)\n",
    "        next_token = token_sampling(y, decisive)\n",
    "        token_ids.append(next_token)\n",
    "\n",
    "    sentence = sp_en.decode(token_ids)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずは訓練データから。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 時間が止まってしまったようでした\n",
      "output: It was a little bit like a sliver.\n",
      "answer: It was as though time had stopped.\n",
      "\n",
      "input: 詳しく伝える時間はないのですが 非常に複雑な課題もこなし 間違えることを嫌います\n",
      "output: I've never seen a lot of people, but I've got to tell you, I'm not going to be able to do anything about the things that I've been hearing about.\n",
      "answer: She does very complex tasks, and I haven't got time to go into them, but the amazing thing about this female is she doesn't like making mistakes.\n",
      "\n",
      "input: 本当に最期となったら どんな言葉を誰から 聞きたいですか?\n",
      "output: What are you going to do with this person, who's a kid, who's a guy like, \"What is your hand?\"\n",
      "answer: What do you want to hear at the very end, and from whom would you like to hear it?\n",
      "\n",
      "input: 僕の名前は テイラー・ウィルソン\n",
      "output: My name is Martin Luther King.\n",
      "answer: So my name is Taylor Wilson.\n",
      "\n",
      "input: よく考えないで作るから こういう事が起こる\n",
      "output: You're thinking about it, and you're thinking, \"This is a really good thing.\n",
      "answer: It's letting stuff happen without thinking about it.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "for _ in range(n):\n",
    "    i = random.randint(0, len(train_dataset))\n",
    "    x, _, t = train_dataset[i]\n",
    "    x = sp_ja.decode(x.tolist())\n",
    "    t = sp_en.decode(t.tolist())\n",
    "    print(\"input:\", x)\n",
    "    print(\"output:\", translate(model, x))\n",
    "    print(\"answer:\", t)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "あまりよくないね。\n",
    "\n",
    "訓練データに含まれていないものも試してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 非政府組織 企業 その他の市民団体が 他の人々の生活に影響を及ぼす強大な力を備えています\n",
      "output: The most important social networking of social media is a community of people who are trying to help people who have access to the environment.\n",
      "answer: They, businesses, other citizens' groups, have enormous power to affect the lives of our fellow human beings.\n",
      "\n",
      "input: 真面目な話エネルギー省は フラッキングには関わっていません\n",
      "output: So, the first thing I want to do is to make a difference, and I think that's a good thing.\n",
      "answer: I mean seriously, the Department of Energy did not have anything to do with fracking.\n",
      "\n",
      "input: 数万個の銀河系を調べることにより 発見した42個の超新星が 我々の頭上にある宇宙の理解を 覆したのならば 数十億の銀河系を調べることにより 42個の何倍ほどの超新星を得て 予測と全く一致しないようなものを 見出すことになるのでしょうか\n",
      "output: We're going to see the next generation of planets, and we're going to see the Earth's genome, and we're going to see the next generation of planets, and we're going to see the problem of the Earth's atmosphere, and we're going to see the genomes of the Earth's surface, and we're going to see the next generation of planets.\n",
      "answer: But if looking through tens of thousands of galaxies revealed 42 supernovae that turned our understanding of the universe on its head, when we're working with billions of galaxies, how many more times are we going to find 42 points that don't quite match what we expect?\n",
      "\n",
      "input: YB:こちらは、ウィンドサーフィンとスキーを組み合わせた発明品です\n",
      "output: BF: This is a friend of mine, a friend of mine, a new musical installation.\n",
      "answer: YB: Combination of windsurfing and skiing into this invention there.\n",
      "\n",
      "input: クロロフィルが周囲にたくさんあるときには 緑色の光をよく感知します\n",
      "output: And when you see the surface of the brain, you see that the light is very, very different from the brain.\n",
      "answer: When there's a lot of chlorophyll around, they see a lot of green light.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "for _ in range(n):\n",
    "    i = random.randint(0, len(test_dataset))\n",
    "    x, _, t = test_dataset[i]\n",
    "    x = sp_ja.decode(x.tolist())\n",
    "    t = sp_en.decode(t.tolist())\n",
    "    print(\"input:\", x)\n",
    "    print(\"output:\", translate(model, x))\n",
    "    print(\"answer:\", t)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: ありがとう\n",
      "output: Thank you.\n",
      "\n",
      "input: 猫はかわいいのです\n",
      "output: They're not going to be able to get their hands.\n",
      "\n",
      "input: 上手く文章が書けるようになりました\n",
      "output: The first thing I did was I was working on the Internet.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "sentences = [\n",
    "    \"ありがとう\",\n",
    "    \"猫はかわいいのです\",\n",
    "    \"上手く文章が書けるようになりました\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(\"input:\", sentence)\n",
    "    print(\"output:\", translate(model, sentence))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "びみょう。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
